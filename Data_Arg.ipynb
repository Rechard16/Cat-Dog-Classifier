{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Layer,add,Input,concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(\"X_train\", \"rb\"))\n",
    "y_train = pickle.load(open(\"y_train\", \"rb\"))\n",
    "X_test = pickle.load(open(\"X_test\", \"rb\"))\n",
    "y_test = pickle.load(open(\"y_test\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test/255.0\n",
    "X_train=X_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.002))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.002))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.002))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3410e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 37s 105ms/step - loss: 0.3402 - accuracy: 0.9460 - auc: 0.9865 - precision: 0.9546 - recall: 0.9354 - val_loss: 0.3994 - val_accuracy: 0.9302 - val_auc: 0.9830 - val_precision: 0.9580 - val_recall: 0.9007\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.3463 - accuracy: 0.9550 - auc: 0.9911 - precision: 0.9612 - recall: 0.9473 - val_loss: 0.3899 - val_accuracy: 0.9355 - val_auc: 0.9835 - val_precision: 0.9563 - val_recall: 0.9135\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3433 - accuracy: 0.9555 - auc: 0.9908 - precision: 0.9606 - recall: 0.9491 - val_loss: 0.3902 - val_accuracy: 0.9340 - val_auc: 0.9834 - val_precision: 0.9530 - val_recall: 0.9137\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.3396 - accuracy: 0.9578 - auc: 0.9915 - precision: 0.9663 - recall: 0.9479 - val_loss: 0.3822 - val_accuracy: 0.9367 - val_auc: 0.9840 - val_precision: 0.9498 - val_recall: 0.9229\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3285 - accuracy: 0.9583 - auc: 0.9919 - precision: 0.9647 - recall: 0.9506 - val_loss: 0.3949 - val_accuracy: 0.9276 - val_auc: 0.9836 - val_precision: 0.9629 - val_recall: 0.8902\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3212 - accuracy: 0.9581 - auc: 0.9921 - precision: 0.9638 - recall: 0.9511 - val_loss: 0.3731 - val_accuracy: 0.9334 - val_auc: 0.9841 - val_precision: 0.9563 - val_recall: 0.9091\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3165 - accuracy: 0.9564 - auc: 0.9912 - precision: 0.9638 - recall: 0.9476 - val_loss: 0.3538 - val_accuracy: 0.9345 - val_auc: 0.9839 - val_precision: 0.9560 - val_recall: 0.9117\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.2973 - accuracy: 0.9586 - auc: 0.9923 - precision: 0.9649 - recall: 0.9510 - val_loss: 0.3644 - val_accuracy: 0.9355 - val_auc: 0.9829 - val_precision: 0.9415 - val_recall: 0.9295\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.2968 - accuracy: 0.9589 - auc: 0.9923 - precision: 0.9647 - recall: 0.9517 - val_loss: 0.3699 - val_accuracy: 0.9328 - val_auc: 0.9831 - val_precision: 0.9540 - val_recall: 0.9102\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3099 - accuracy: 0.9568 - auc: 0.9916 - precision: 0.9633 - recall: 0.9489 - val_loss: 0.3871 - val_accuracy: 0.9336 - val_auc: 0.9817 - val_precision: 0.9589 - val_recall: 0.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cd7315f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3420e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.005))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.005))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.005))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3420e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3846 - accuracy: 0.9484 - auc: 0.9877 - precision: 0.9546 - recall: 0.9405 - val_loss: 0.3849 - val_accuracy: 0.9363 - val_auc: 0.9836 - val_precision: 0.9494 - val_recall: 0.9225\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3373 - accuracy: 0.9510 - auc: 0.9901 - precision: 0.9556 - recall: 0.9449 - val_loss: 0.3885 - val_accuracy: 0.9351 - val_auc: 0.9835 - val_precision: 0.9573 - val_recall: 0.9115\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3499 - accuracy: 0.9505 - auc: 0.9894 - precision: 0.9563 - recall: 0.9432 - val_loss: 0.4077 - val_accuracy: 0.9319 - val_auc: 0.9822 - val_precision: 0.9551 - val_recall: 0.9071\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3365 - accuracy: 0.9541 - auc: 0.9903 - precision: 0.9591 - recall: 0.9477 - val_loss: 0.3887 - val_accuracy: 0.9367 - val_auc: 0.9835 - val_precision: 0.9494 - val_recall: 0.9233\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3366 - accuracy: 0.9526 - auc: 0.9903 - precision: 0.9582 - recall: 0.9456 - val_loss: 0.3625 - val_accuracy: 0.9351 - val_auc: 0.9832 - val_precision: 0.9534 - val_recall: 0.9157\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.3232 - accuracy: 0.9535 - auc: 0.9905 - precision: 0.9569 - recall: 0.9488 - val_loss: 0.3814 - val_accuracy: 0.9298 - val_auc: 0.9831 - val_precision: 0.9102 - val_recall: 0.9545\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3600 - accuracy: 0.9518 - auc: 0.9895 - precision: 0.9524 - recall: 0.9502 - val_loss: 0.3842 - val_accuracy: 0.9328 - val_auc: 0.9824 - val_precision: 0.9523 - val_recall: 0.9119\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3359 - accuracy: 0.9536 - auc: 0.9902 - precision: 0.9574 - recall: 0.9486 - val_loss: 0.3677 - val_accuracy: 0.9320 - val_auc: 0.9836 - val_precision: 0.9479 - val_recall: 0.9150\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3045 - accuracy: 0.9565 - auc: 0.9913 - precision: 0.9592 - recall: 0.9527 - val_loss: 0.3754 - val_accuracy: 0.9371 - val_auc: 0.9832 - val_precision: 0.9537 - val_recall: 0.9194\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3068 - accuracy: 0.9559 - auc: 0.9907 - precision: 0.9598 - recall: 0.9508 - val_loss: 0.3405 - val_accuracy: 0.9363 - val_auc: 0.9831 - val_precision: 0.9404 - val_recall: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261f0c45b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3430e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3430e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 30s 100ms/step - loss: 0.3600 - accuracy: 0.9513 - auc: 0.9892 - precision: 0.9536 - recall: 0.9478 - val_loss: 0.4305 - val_accuracy: 0.9334 - val_auc: 0.9822 - val_precision: 0.9360 - val_recall: 0.9313\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 28s 100ms/step - loss: 0.3521 - accuracy: 0.9519 - auc: 0.9891 - precision: 0.9571 - recall: 0.9452 - val_loss: 0.3971 - val_accuracy: 0.9319 - val_auc: 0.9826 - val_precision: 0.9558 - val_recall: 0.9064\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3796 - accuracy: 0.9514 - auc: 0.9884 - precision: 0.9550 - recall: 0.9465 - val_loss: 0.3929 - val_accuracy: 0.9362 - val_auc: 0.9828 - val_precision: 0.9441 - val_recall: 0.9280\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3567 - accuracy: 0.9524 - auc: 0.9897 - precision: 0.9568 - recall: 0.9466 - val_loss: 0.4033 - val_accuracy: 0.9303 - val_auc: 0.9832 - val_precision: 0.9687 - val_recall: 0.8902\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.3705 - accuracy: 0.9513 - auc: 0.9886 - precision: 0.9587 - recall: 0.9422 - val_loss: 0.3937 - val_accuracy: 0.9372 - val_auc: 0.9829 - val_precision: 0.9456 - val_recall: 0.9284\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3557 - accuracy: 0.9534 - auc: 0.9895 - precision: 0.9593 - recall: 0.9460 - val_loss: 0.4096 - val_accuracy: 0.9335 - val_auc: 0.9815 - val_precision: 0.9372 - val_recall: 0.9302\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3660 - accuracy: 0.9520 - auc: 0.9890 - precision: 0.9580 - recall: 0.9446 - val_loss: 0.3892 - val_accuracy: 0.9328 - val_auc: 0.9814 - val_precision: 0.9388 - val_recall: 0.9266\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3566 - accuracy: 0.9528 - auc: 0.9895 - precision: 0.9584 - recall: 0.9458 - val_loss: 0.4292 - val_accuracy: 0.9315 - val_auc: 0.9822 - val_precision: 0.9243 - val_recall: 0.9409\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3713 - accuracy: 0.9524 - auc: 0.9894 - precision: 0.9583 - recall: 0.9451 - val_loss: 0.4011 - val_accuracy: 0.9338 - val_auc: 0.9823 - val_precision: 0.9530 - val_recall: 0.9132\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.3675 - accuracy: 0.9527 - auc: 0.9899 - precision: 0.9581 - recall: 0.9460 - val_loss: 0.4104 - val_accuracy: 0.9326 - val_auc: 0.9811 - val_precision: 0.9292 - val_recall: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26241621610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3440e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    #x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    #x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    #x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3440e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "284/284 [==============================] - 32s 95ms/step - loss: 0.1284 - accuracy: 0.9881 - auc: 0.9989 - precision: 0.9875 - recall: 0.9885 - val_loss: 0.3683 - val_accuracy: 0.9276 - val_auc: 0.9746 - val_precision: 0.9304 - val_recall: 0.9251\n",
      "Epoch 2/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.1166 - accuracy: 0.9910 - auc: 0.9994 - precision: 0.9900 - recall: 0.9919 - val_loss: 0.3403 - val_accuracy: 0.9303 - val_auc: 0.9721 - val_precision: 0.9335 - val_recall: 0.9275\n",
      "Epoch 3/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.1058 - accuracy: 0.9918 - auc: 0.9995 - precision: 0.9907 - recall: 0.9928 - val_loss: 0.3300 - val_accuracy: 0.9309 - val_auc: 0.9738 - val_precision: 0.9494 - val_recall: 0.9110\n",
      "Epoch 4/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.1028 - accuracy: 0.9933 - auc: 0.9995 - precision: 0.9925 - recall: 0.9941 - val_loss: 0.4142 - val_accuracy: 0.9302 - val_auc: 0.9659 - val_precision: 0.9465 - val_recall: 0.9128\n",
      "Epoch 5/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.1097 - accuracy: 0.9938 - auc: 0.9996 - precision: 0.9939 - recall: 0.9936 - val_loss: 0.3643 - val_accuracy: 0.9267 - val_auc: 0.9703 - val_precision: 0.9203 - val_recall: 0.9352\n",
      "Epoch 6/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0747 - accuracy: 0.9954 - auc: 0.9998 - precision: 0.9952 - recall: 0.9954 - val_loss: 0.3339 - val_accuracy: 0.9265 - val_auc: 0.9721 - val_precision: 0.9147 - val_recall: 0.9416\n",
      "Epoch 7/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0874 - accuracy: 0.9943 - auc: 0.9997 - precision: 0.9938 - recall: 0.9948 - val_loss: 0.3579 - val_accuracy: 0.9304 - val_auc: 0.9724 - val_precision: 0.9346 - val_recall: 0.9264\n",
      "Epoch 8/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0740 - accuracy: 0.9956 - auc: 0.9998 - precision: 0.9953 - recall: 0.9959 - val_loss: 0.4261 - val_accuracy: 0.9292 - val_auc: 0.9633 - val_precision: 0.9245 - val_recall: 0.9356\n",
      "Epoch 9/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0719 - accuracy: 0.9959 - auc: 0.9998 - precision: 0.9961 - recall: 0.9956 - val_loss: 0.3950 - val_accuracy: 0.9308 - val_auc: 0.9668 - val_precision: 0.9517 - val_recall: 0.9084\n",
      "Epoch 10/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0702 - accuracy: 0.9964 - auc: 0.9998 - precision: 0.9963 - recall: 0.9964 - val_loss: 0.3721 - val_accuracy: 0.9307 - val_auc: 0.9700 - val_precision: 0.9421 - val_recall: 0.9185\n",
      "Epoch 11/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0926 - accuracy: 0.9953 - auc: 0.9996 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.3868 - val_accuracy: 0.9332 - val_auc: 0.9685 - val_precision: 0.9375 - val_recall: 0.9291\n",
      "Epoch 12/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0586 - accuracy: 0.9970 - auc: 0.9999 - precision: 0.9970 - recall: 0.9969 - val_loss: 0.4054 - val_accuracy: 0.9298 - val_auc: 0.9667 - val_precision: 0.9388 - val_recall: 0.9203\n",
      "Epoch 13/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0696 - accuracy: 0.9962 - auc: 0.9998 - precision: 0.9959 - recall: 0.9964 - val_loss: 0.4026 - val_accuracy: 0.9285 - val_auc: 0.9670 - val_precision: 0.9500 - val_recall: 0.9053\n",
      "Epoch 14/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0565 - accuracy: 0.9974 - auc: 0.9998 - precision: 0.9974 - recall: 0.9973 - val_loss: 0.4267 - val_accuracy: 0.9272 - val_auc: 0.9636 - val_precision: 0.9503 - val_recall: 0.9025\n",
      "Epoch 15/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0832 - accuracy: 0.9956 - auc: 0.9998 - precision: 0.9954 - recall: 0.9957 - val_loss: 0.4393 - val_accuracy: 0.9306 - val_auc: 0.9642 - val_precision: 0.9397 - val_recall: 0.9209\n",
      "Epoch 16/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0690 - accuracy: 0.9970 - auc: 0.9998 - precision: 0.9972 - recall: 0.9968 - val_loss: 0.3613 - val_accuracy: 0.9304 - val_auc: 0.9685 - val_precision: 0.9451 - val_recall: 0.9148\n",
      "Epoch 17/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0670 - accuracy: 0.9972 - auc: 0.9997 - precision: 0.9970 - recall: 0.9974 - val_loss: 0.3641 - val_accuracy: 0.9318 - val_auc: 0.9683 - val_precision: 0.9572 - val_recall: 0.9047\n",
      "Epoch 18/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0769 - accuracy: 0.9960 - auc: 0.9997 - precision: 0.9959 - recall: 0.9960 - val_loss: 0.4391 - val_accuracy: 0.9261 - val_auc: 0.9624 - val_precision: 0.9354 - val_recall: 0.9163\n",
      "Epoch 19/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0678 - accuracy: 0.9965 - auc: 0.9997 - precision: 0.9963 - recall: 0.9968 - val_loss: 0.3955 - val_accuracy: 0.9267 - val_auc: 0.9673 - val_precision: 0.9369 - val_recall: 0.9159\n",
      "Epoch 20/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0564 - accuracy: 0.9971 - auc: 0.9998 - precision: 0.9967 - recall: 0.9975 - val_loss: 0.4182 - val_accuracy: 0.9300 - val_auc: 0.9618 - val_precision: 0.9361 - val_recall: 0.9238\n",
      "Epoch 21/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0553 - accuracy: 0.9979 - auc: 0.9999 - precision: 0.9975 - recall: 0.9982 - val_loss: 0.4960 - val_accuracy: 0.9283 - val_auc: 0.9564 - val_precision: 0.9561 - val_recall: 0.8987\n",
      "Epoch 22/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0620 - accuracy: 0.9966 - auc: 0.9998 - precision: 0.9958 - recall: 0.9973 - val_loss: 0.4301 - val_accuracy: 0.9288 - val_auc: 0.9633 - val_precision: 0.9439 - val_recall: 0.9126\n",
      "Epoch 23/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0703 - accuracy: 0.9968 - auc: 0.9997 - precision: 0.9962 - recall: 0.9973 - val_loss: 0.4042 - val_accuracy: 0.9267 - val_auc: 0.9635 - val_precision: 0.9271 - val_recall: 0.9271\n",
      "Epoch 24/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0523 - accuracy: 0.9976 - auc: 0.9998 - precision: 0.9970 - recall: 0.9981 - val_loss: 0.4111 - val_accuracy: 0.9246 - val_auc: 0.9613 - val_precision: 0.9181 - val_recall: 0.9332\n",
      "Epoch 25/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0689 - accuracy: 0.9970 - auc: 0.9997 - precision: 0.9967 - recall: 0.9972 - val_loss: 0.3842 - val_accuracy: 0.9285 - val_auc: 0.9675 - val_precision: 0.9307 - val_recall: 0.9266\n",
      "Epoch 26/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0628 - accuracy: 0.9972 - auc: 0.9998 - precision: 0.9969 - recall: 0.9974 - val_loss: 0.4035 - val_accuracy: 0.9275 - val_auc: 0.9642 - val_precision: 0.9186 - val_recall: 0.9389\n",
      "Epoch 27/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0724 - accuracy: 0.9966 - auc: 0.9998 - precision: 0.9960 - recall: 0.9972 - val_loss: 0.4613 - val_accuracy: 0.9257 - val_auc: 0.9575 - val_precision: 0.9462 - val_recall: 0.9036\n",
      "Epoch 28/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0527 - accuracy: 0.9979 - auc: 0.9999 - precision: 0.9975 - recall: 0.9983 - val_loss: 0.4276 - val_accuracy: 0.9310 - val_auc: 0.9583 - val_precision: 0.9400 - val_recall: 0.9216\n",
      "Epoch 29/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0497 - accuracy: 0.9977 - auc: 0.9998 - precision: 0.9974 - recall: 0.9978 - val_loss: 0.3565 - val_accuracy: 0.9257 - val_auc: 0.9675 - val_precision: 0.9305 - val_recall: 0.9209\n",
      "Epoch 30/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0484 - accuracy: 0.9972 - auc: 0.9998 - precision: 0.9968 - recall: 0.9975 - val_loss: 0.4460 - val_accuracy: 0.9213 - val_auc: 0.9606 - val_precision: 0.9017 - val_recall: 0.9466\n",
      "Epoch 31/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0564 - accuracy: 0.9973 - auc: 0.9999 - precision: 0.9966 - recall: 0.9979 - val_loss: 0.4485 - val_accuracy: 0.9298 - val_auc: 0.9604 - val_precision: 0.9485 - val_recall: 0.9097\n",
      "Epoch 32/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0517 - accuracy: 0.9976 - auc: 0.9998 - precision: 0.9970 - recall: 0.9982 - val_loss: 0.3945 - val_accuracy: 0.9282 - val_auc: 0.9628 - val_precision: 0.9336 - val_recall: 0.9229\n",
      "Epoch 33/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0597 - accuracy: 0.9970 - auc: 0.9999 - precision: 0.9964 - recall: 0.9975 - val_loss: 0.4214 - val_accuracy: 0.9285 - val_auc: 0.9622 - val_precision: 0.9218 - val_recall: 0.9372\n",
      "Epoch 34/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0704 - accuracy: 0.9979 - auc: 0.9998 - precision: 0.9974 - recall: 0.9983 - val_loss: 0.4515 - val_accuracy: 0.9294 - val_auc: 0.9597 - val_precision: 0.9446 - val_recall: 0.9132\n",
      "Epoch 35/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0839 - accuracy: 0.9970 - auc: 0.9997 - precision: 0.9962 - recall: 0.9977 - val_loss: 0.5007 - val_accuracy: 0.9220 - val_auc: 0.9558 - val_precision: 0.9116 - val_recall: 0.9356\n",
      "Epoch 36/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0757 - accuracy: 0.9964 - auc: 0.9997 - precision: 0.9953 - recall: 0.9974 - val_loss: 0.5257 - val_accuracy: 0.9298 - val_auc: 0.9578 - val_precision: 0.9430 - val_recall: 0.9157\n",
      "Epoch 37/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0665 - accuracy: 0.9971 - auc: 0.9998 - precision: 0.9959 - recall: 0.9982 - val_loss: 0.3975 - val_accuracy: 0.9251 - val_auc: 0.9605 - val_precision: 0.9301 - val_recall: 0.9203\n",
      "Epoch 38/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0574 - accuracy: 0.9977 - auc: 0.9997 - precision: 0.9973 - recall: 0.9981 - val_loss: 0.4444 - val_accuracy: 0.9249 - val_auc: 0.9600 - val_precision: 0.9029 - val_recall: 0.9532\n",
      "Epoch 39/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0477 - accuracy: 0.9977 - auc: 0.9999 - precision: 0.9972 - recall: 0.9982 - val_loss: 0.3963 - val_accuracy: 0.9290 - val_auc: 0.9616 - val_precision: 0.9254 - val_recall: 0.9341\n",
      "Epoch 40/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0407 - accuracy: 0.9983 - auc: 0.9999 - precision: 0.9978 - recall: 0.9988 - val_loss: 0.4349 - val_accuracy: 0.9296 - val_auc: 0.9575 - val_precision: 0.9318 - val_recall: 0.9277\n",
      "Epoch 41/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0390 - accuracy: 0.9981 - auc: 0.9999 - precision: 0.9977 - recall: 0.9985 - val_loss: 0.3943 - val_accuracy: 0.9262 - val_auc: 0.9597 - val_precision: 0.9550 - val_recall: 0.8955\n",
      "Epoch 42/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0740 - accuracy: 0.9966 - auc: 0.9997 - precision: 0.9958 - recall: 0.9973 - val_loss: 0.4347 - val_accuracy: 0.9302 - val_auc: 0.9597 - val_precision: 0.9335 - val_recall: 0.9273\n",
      "Epoch 43/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0584 - accuracy: 0.9976 - auc: 0.9998 - precision: 0.9969 - recall: 0.9983 - val_loss: 0.4074 - val_accuracy: 0.9291 - val_auc: 0.9614 - val_precision: 0.9243 - val_recall: 0.9356\n",
      "Epoch 44/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0386 - accuracy: 0.9987 - auc: 0.9999 - precision: 0.9983 - recall: 0.9991 - val_loss: 0.4014 - val_accuracy: 0.9240 - val_auc: 0.9616 - val_precision: 0.9111 - val_recall: 0.9407\n",
      "Epoch 45/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0638 - accuracy: 0.9973 - auc: 0.9996 - precision: 0.9966 - recall: 0.9980 - val_loss: 0.3987 - val_accuracy: 0.9209 - val_auc: 0.9684 - val_precision: 0.9011 - val_recall: 0.9466\n",
      "Epoch 46/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0930 - accuracy: 0.9967 - auc: 0.9998 - precision: 0.9961 - recall: 0.9973 - val_loss: 0.4675 - val_accuracy: 0.9251 - val_auc: 0.9586 - val_precision: 0.9213 - val_recall: 0.9306\n",
      "Epoch 47/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0479 - accuracy: 0.9985 - auc: 0.9999 - precision: 0.9981 - recall: 0.9989 - val_loss: 0.5093 - val_accuracy: 0.9287 - val_auc: 0.9519 - val_precision: 0.9529 - val_recall: 0.9027\n",
      "Epoch 48/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0788 - accuracy: 0.9970 - auc: 0.9997 - precision: 0.9964 - recall: 0.9976 - val_loss: 0.4153 - val_accuracy: 0.9293 - val_auc: 0.9621 - val_precision: 0.9267 - val_recall: 0.9332\n",
      "Epoch 49/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0687 - accuracy: 0.9977 - auc: 0.9997 - precision: 0.9973 - recall: 0.9980 - val_loss: 0.3916 - val_accuracy: 0.9312 - val_auc: 0.9649 - val_precision: 0.9336 - val_recall: 0.9293\n",
      "Epoch 50/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0453 - accuracy: 0.9982 - auc: 0.9999 - precision: 0.9976 - recall: 0.9988 - val_loss: 0.4242 - val_accuracy: 0.9298 - val_auc: 0.9593 - val_precision: 0.9268 - val_recall: 0.9341\n",
      "Epoch 51/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0413 - accuracy: 0.9977 - auc: 0.9998 - precision: 0.9969 - recall: 0.9984 - val_loss: 0.4696 - val_accuracy: 0.9261 - val_auc: 0.9566 - val_precision: 0.9225 - val_recall: 0.9313\n",
      "Epoch 52/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0830 - accuracy: 0.9967 - auc: 0.9996 - precision: 0.9958 - recall: 0.9976 - val_loss: 0.4344 - val_accuracy: 0.9246 - val_auc: 0.9670 - val_precision: 0.9352 - val_recall: 0.9132\n",
      "Epoch 53/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0788 - accuracy: 0.9977 - auc: 0.9997 - precision: 0.9974 - recall: 0.9979 - val_loss: 0.5099 - val_accuracy: 0.9320 - val_auc: 0.9546 - val_precision: 0.9419 - val_recall: 0.9216\n",
      "Epoch 54/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0442 - accuracy: 0.9987 - auc: 0.9998 - precision: 0.9985 - recall: 0.9989 - val_loss: 0.4578 - val_accuracy: 0.9290 - val_auc: 0.9547 - val_precision: 0.9488 - val_recall: 0.9078\n",
      "Epoch 55/60\n",
      "284/284 [==============================] - 24s 86ms/step - loss: 0.0433 - accuracy: 0.9983 - auc: 0.9998 - precision: 0.9978 - recall: 0.9989 - val_loss: 0.4302 - val_accuracy: 0.9301 - val_auc: 0.9562 - val_precision: 0.9438 - val_recall: 0.9154\n",
      "Epoch 56/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0530 - accuracy: 0.9980 - auc: 0.9998 - precision: 0.9977 - recall: 0.9983 - val_loss: 0.5033 - val_accuracy: 0.9244 - val_auc: 0.9554 - val_precision: 0.9405 - val_recall: 0.9069\n",
      "Epoch 57/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0513 - accuracy: 0.9984 - auc: 0.9998 - precision: 0.9981 - recall: 0.9987 - val_loss: 0.3863 - val_accuracy: 0.9261 - val_auc: 0.9633 - val_precision: 0.9308 - val_recall: 0.9216\n",
      "Epoch 58/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0871 - accuracy: 0.9965 - auc: 0.9995 - precision: 0.9958 - recall: 0.9972 - val_loss: 0.4840 - val_accuracy: 0.9288 - val_auc: 0.9603 - val_precision: 0.9377 - val_recall: 0.9194\n",
      "Epoch 59/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0591 - accuracy: 0.9982 - auc: 0.9998 - precision: 0.9979 - recall: 0.9985 - val_loss: 0.3842 - val_accuracy: 0.9301 - val_auc: 0.9669 - val_precision: 0.9246 - val_recall: 0.9374\n",
      "Epoch 60/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0750 - accuracy: 0.9974 - auc: 0.9996 - precision: 0.9972 - recall: 0.9976 - val_loss: 0.4888 - val_accuracy: 0.9309 - val_auc: 0.9560 - val_precision: 0.9322 - val_recall: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x279688f2640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=60, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3500e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3500e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1133/1133 [==============================] - 37s 29ms/step - loss: 0.1343 - accuracy: 0.9915 - auc: 0.9987 - precision: 0.9912 - recall: 0.9917 - val_loss: 0.3978 - val_accuracy: 0.9246 - val_auc: 0.9661 - val_precision: 0.9283 - val_recall: 0.9212\n",
      "Epoch 2/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.0900 - accuracy: 0.9962 - auc: 0.9996 - precision: 0.9955 - recall: 0.9968 - val_loss: 0.4159 - val_accuracy: 0.9258 - val_auc: 0.9658 - val_precision: 0.9144 - val_recall: 0.9405\n",
      "Epoch 3/10\n",
      "1133/1133 [==============================] - 31s 28ms/step - loss: 0.1053 - accuracy: 0.9959 - auc: 0.9994 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4510 - val_accuracy: 0.9243 - val_auc: 0.9634 - val_precision: 0.9279 - val_recall: 0.9209\n",
      "Epoch 4/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.1088 - accuracy: 0.9950 - auc: 0.9994 - precision: 0.9948 - recall: 0.9952 - val_loss: 0.4248 - val_accuracy: 0.9298 - val_auc: 0.9622 - val_precision: 0.9300 - val_recall: 0.9304\n",
      "Epoch 5/10\n",
      "1133/1133 [==============================] - 32s 28ms/step - loss: 0.0965 - accuracy: 0.9951 - auc: 0.9994 - precision: 0.9947 - recall: 0.9954 - val_loss: 0.4683 - val_accuracy: 0.9257 - val_auc: 0.9618 - val_precision: 0.9247 - val_recall: 0.9277\n",
      "Epoch 6/10\n",
      "1133/1133 [==============================] - 31s 28ms/step - loss: 0.0924 - accuracy: 0.9961 - auc: 0.9995 - precision: 0.9957 - recall: 0.9964 - val_loss: 0.6560 - val_accuracy: 0.9267 - val_auc: 0.9574 - val_precision: 0.9232 - val_recall: 0.9317\n",
      "Epoch 7/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.1270 - accuracy: 0.9950 - auc: 0.9993 - precision: 0.9945 - recall: 0.9954 - val_loss: 0.5070 - val_accuracy: 0.9243 - val_auc: 0.9591 - val_precision: 0.9168 - val_recall: 0.9341\n",
      "Epoch 8/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.1179 - accuracy: 0.9945 - auc: 0.9995 - precision: 0.9941 - recall: 0.9949 - val_loss: 0.4286 - val_accuracy: 0.9229 - val_auc: 0.9636 - val_precision: 0.9079 - val_recall: 0.9422\n",
      "Epoch 9/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.0880 - accuracy: 0.9965 - auc: 0.9998 - precision: 0.9962 - recall: 0.9969 - val_loss: 0.6113 - val_accuracy: 0.9300 - val_auc: 0.9528 - val_precision: 0.9499 - val_recall: 0.9086\n",
      "Epoch 10/10\n",
      "1133/1133 [==============================] - 29s 25ms/step - loss: 0.0973 - accuracy: 0.9953 - auc: 0.9994 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.5143 - val_accuracy: 0.9170 - val_auc: 0.9597 - val_precision: 0.8949 - val_recall: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8c3263160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3510e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    #x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    #x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    #x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3510e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "284/284 [==============================] - 43s 102ms/step - loss: 0.1931 - accuracy: 0.9856 - auc: 0.9979 - precision: 0.9916 - recall: 0.9792 - val_loss: 0.5738 - val_accuracy: 0.9272 - val_auc: 0.9617 - val_precision: 0.9255 - val_recall: 0.9302\n",
      "Epoch 2/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1773 - accuracy: 0.9947 - auc: 0.9995 - precision: 0.9954 - recall: 0.9939 - val_loss: 0.5629 - val_accuracy: 0.9272 - val_auc: 0.9629 - val_precision: 0.9257 - val_recall: 0.9299\n",
      "Epoch 3/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1804 - accuracy: 0.9948 - auc: 0.9995 - precision: 0.9955 - recall: 0.9940 - val_loss: 0.5546 - val_accuracy: 0.9261 - val_auc: 0.9623 - val_precision: 0.9185 - val_recall: 0.9361\n",
      "Epoch 4/40\n",
      "284/284 [==============================] - 26s 91ms/step - loss: 0.1805 - accuracy: 0.9951 - auc: 0.9994 - precision: 0.9958 - recall: 0.9944 - val_loss: 0.5304 - val_accuracy: 0.9283 - val_auc: 0.9645 - val_precision: 0.9584 - val_recall: 0.8963\n",
      "Epoch 5/40\n",
      "284/284 [==============================] - 26s 90ms/step - loss: 0.1713 - accuracy: 0.9951 - auc: 0.9996 - precision: 0.9959 - recall: 0.9943 - val_loss: 0.6743 - val_accuracy: 0.9285 - val_auc: 0.9552 - val_precision: 0.9344 - val_recall: 0.9225\n",
      "Epoch 6/40\n",
      "284/284 [==============================] - 26s 93ms/step - loss: 0.1647 - accuracy: 0.9951 - auc: 0.9995 - precision: 0.9960 - recall: 0.9941 - val_loss: 0.5530 - val_accuracy: 0.9236 - val_auc: 0.9633 - val_precision: 0.9135 - val_recall: 0.9367\n",
      "Epoch 7/40\n",
      "284/284 [==============================] - 26s 93ms/step - loss: 0.2164 - accuracy: 0.9918 - auc: 0.9992 - precision: 0.9939 - recall: 0.9895 - val_loss: 0.6062 - val_accuracy: 0.9318 - val_auc: 0.9596 - val_precision: 0.9358 - val_recall: 0.9280\n",
      "Epoch 8/40\n",
      "284/284 [==============================] - 26s 91ms/step - loss: 0.1679 - accuracy: 0.9944 - auc: 0.9995 - precision: 0.9954 - recall: 0.9933 - val_loss: 0.6098 - val_accuracy: 0.9256 - val_auc: 0.9607 - val_precision: 0.9119 - val_recall: 0.9431\n",
      "Epoch 9/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1451 - accuracy: 0.9956 - auc: 0.9997 - precision: 0.9966 - recall: 0.9945 - val_loss: 0.5926 - val_accuracy: 0.9286 - val_auc: 0.9607 - val_precision: 0.9229 - val_recall: 0.9361\n",
      "Epoch 10/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1434 - accuracy: 0.9950 - auc: 0.9995 - precision: 0.9959 - recall: 0.9939 - val_loss: 0.5606 - val_accuracy: 0.9238 - val_auc: 0.9630 - val_precision: 0.9301 - val_recall: 0.9174\n",
      "Epoch 11/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1791 - accuracy: 0.9951 - auc: 0.9996 - precision: 0.9961 - recall: 0.9940 - val_loss: 0.5954 - val_accuracy: 0.9277 - val_auc: 0.9582 - val_precision: 0.9304 - val_recall: 0.9253\n",
      "Epoch 12/40\n",
      "284/284 [==============================] - 25s 90ms/step - loss: 0.1623 - accuracy: 0.9951 - auc: 0.9996 - precision: 0.9963 - recall: 0.9938 - val_loss: 0.6644 - val_accuracy: 0.9247 - val_auc: 0.9555 - val_precision: 0.9093 - val_recall: 0.9444\n",
      "Epoch 13/40\n",
      "284/284 [==============================] - 26s 91ms/step - loss: 0.1462 - accuracy: 0.9955 - auc: 0.9995 - precision: 0.9965 - recall: 0.9945 - val_loss: 0.6702 - val_accuracy: 0.9277 - val_auc: 0.9549 - val_precision: 0.9417 - val_recall: 0.9126\n",
      "Epoch 14/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1566 - accuracy: 0.9956 - auc: 0.9996 - precision: 0.9962 - recall: 0.9950 - val_loss: 0.6901 - val_accuracy: 0.9212 - val_auc: 0.9562 - val_precision: 0.9045 - val_recall: 0.9427\n",
      "Epoch 15/40\n",
      "284/284 [==============================] - 27s 94ms/step - loss: 0.1799 - accuracy: 0.9938 - auc: 0.9995 - precision: 0.9949 - recall: 0.9926 - val_loss: 0.5973 - val_accuracy: 0.9279 - val_auc: 0.9627 - val_precision: 0.9219 - val_recall: 0.9359\n",
      "Epoch 16/40\n",
      "284/284 [==============================] - 26s 91ms/step - loss: 0.1706 - accuracy: 0.9951 - auc: 0.9996 - precision: 0.9959 - recall: 0.9941 - val_loss: 0.6268 - val_accuracy: 0.9312 - val_auc: 0.9600 - val_precision: 0.9426 - val_recall: 0.9192\n",
      "Epoch 17/40\n",
      "284/284 [==============================] - 26s 91ms/step - loss: 0.1576 - accuracy: 0.9961 - auc: 0.9997 - precision: 0.9965 - recall: 0.9955 - val_loss: 0.5921 - val_accuracy: 0.9312 - val_auc: 0.9561 - val_precision: 0.9386 - val_recall: 0.9236\n",
      "Epoch 18/40\n",
      "284/284 [==============================] - 26s 92ms/step - loss: 0.1338 - accuracy: 0.9956 - auc: 0.9996 - precision: 0.9965 - recall: 0.9947 - val_loss: 0.6400 - val_accuracy: 0.9285 - val_auc: 0.9564 - val_precision: 0.9255 - val_recall: 0.9328\n",
      "Epoch 19/40\n",
      "284/284 [==============================] - 26s 93ms/step - loss: 0.1701 - accuracy: 0.9949 - auc: 0.9996 - precision: 0.9963 - recall: 0.9934 - val_loss: 0.6770 - val_accuracy: 0.9233 - val_auc: 0.9541 - val_precision: 0.9015 - val_recall: 0.9512\n",
      "Epoch 20/40\n",
      "284/284 [==============================] - 27s 94ms/step - loss: 0.1376 - accuracy: 0.9960 - auc: 0.9996 - precision: 0.9967 - recall: 0.9952 - val_loss: 0.5742 - val_accuracy: 0.9261 - val_auc: 0.9590 - val_precision: 0.9408 - val_recall: 0.9104\n",
      "Epoch 21/40\n",
      "284/284 [==============================] - 26s 93ms/step - loss: 0.1566 - accuracy: 0.9953 - auc: 0.9995 - precision: 0.9961 - recall: 0.9944 - val_loss: 0.5863 - val_accuracy: 0.9283 - val_auc: 0.9612 - val_precision: 0.9256 - val_recall: 0.9324\n",
      "Epoch 22/40\n",
      "284/284 [==============================] - 27s 93ms/step - loss: 0.1486 - accuracy: 0.9957 - auc: 0.9995 - precision: 0.9963 - recall: 0.9949 - val_loss: 0.5700 - val_accuracy: 0.9307 - val_auc: 0.9587 - val_precision: 0.9312 - val_recall: 0.9308\n",
      "Epoch 23/40\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1444 - accuracy: 0.9950 - auc: 0.9995 - precision: 0.9959 - recall: 0.9941 - val_loss: 0.6030 - val_accuracy: 0.9267 - val_auc: 0.9576 - val_precision: 0.9273 - val_recall: 0.9269\n",
      "Epoch 24/40\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.1643 - accuracy: 0.9956 - auc: 0.9996 - precision: 0.9964 - recall: 0.9946 - val_loss: 0.6043 - val_accuracy: 0.9269 - val_auc: 0.9593 - val_precision: 0.9371 - val_recall: 0.9161\n",
      "Epoch 25/40\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.1471 - accuracy: 0.9958 - auc: 0.9997 - precision: 0.9967 - recall: 0.9948 - val_loss: 0.5126 - val_accuracy: 0.9258 - val_auc: 0.9623 - val_precision: 0.9354 - val_recall: 0.9157\n",
      "Epoch 26/40\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.1395 - accuracy: 0.9961 - auc: 0.9996 - precision: 0.9965 - recall: 0.9955 - val_loss: 0.5468 - val_accuracy: 0.9319 - val_auc: 0.9638 - val_precision: 0.9299 - val_recall: 0.9350\n",
      "Epoch 27/40\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.1647 - accuracy: 0.9952 - auc: 0.9997 - precision: 0.9959 - recall: 0.9944 - val_loss: 0.6301 - val_accuracy: 0.9248 - val_auc: 0.9565 - val_precision: 0.9368 - val_recall: 0.9119\n",
      "Epoch 28/40\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.1406 - accuracy: 0.9964 - auc: 0.9996 - precision: 0.9973 - recall: 0.9953 - val_loss: 0.6142 - val_accuracy: 0.9287 - val_auc: 0.9583 - val_precision: 0.9477 - val_recall: 0.9082\n",
      "Epoch 29/40\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.1964 - accuracy: 0.9947 - auc: 0.9994 - precision: 0.9959 - recall: 0.9933 - val_loss: 0.5508 - val_accuracy: 0.9289 - val_auc: 0.9623 - val_precision: 0.9344 - val_recall: 0.9233\n",
      "Epoch 30/40\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1616 - accuracy: 0.9957 - auc: 0.9996 - precision: 0.9965 - recall: 0.9948 - val_loss: 0.5977 - val_accuracy: 0.9308 - val_auc: 0.9588 - val_precision: 0.9407 - val_recall: 0.9203\n",
      "Epoch 31/40\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.1679 - accuracy: 0.9958 - auc: 0.9996 - precision: 0.9965 - recall: 0.9951 - val_loss: 0.5887 - val_accuracy: 0.9244 - val_auc: 0.9561 - val_precision: 0.9290 - val_recall: 0.9198\n",
      "Epoch 32/40\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1304 - accuracy: 0.9966 - auc: 0.9998 - precision: 0.9970 - recall: 0.9962 - val_loss: 0.4703 - val_accuracy: 0.9247 - val_auc: 0.9642 - val_precision: 0.9426 - val_recall: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1436 - accuracy: 0.9956 - auc: 0.9995 - precision: 0.9965 - recall: 0.9945 - val_loss: 0.6170 - val_accuracy: 0.9261 - val_auc: 0.9593 - val_precision: 0.9130 - val_recall: 0.9429\n",
      "Epoch 34/40\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1310 - accuracy: 0.9963 - auc: 0.9997 - precision: 0.9969 - recall: 0.9957 - val_loss: 0.4325 - val_accuracy: 0.9303 - val_auc: 0.9684 - val_precision: 0.9453 - val_recall: 0.9143\n",
      "Epoch 35/40\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1615 - accuracy: 0.9944 - auc: 0.9995 - precision: 0.9952 - recall: 0.9935 - val_loss: 0.5928 - val_accuracy: 0.9257 - val_auc: 0.9599 - val_precision: 0.9262 - val_recall: 0.9260\n",
      "Epoch 36/40\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1386 - accuracy: 0.9965 - auc: 0.9995 - precision: 0.9973 - recall: 0.9957 - val_loss: 0.5432 - val_accuracy: 0.9272 - val_auc: 0.9592 - val_precision: 0.9234 - val_recall: 0.9326\n",
      "Epoch 37/40\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1508 - accuracy: 0.9954 - auc: 0.9996 - precision: 0.9961 - recall: 0.9945 - val_loss: 0.6171 - val_accuracy: 0.9309 - val_auc: 0.9562 - val_precision: 0.9405 - val_recall: 0.9207\n",
      "Epoch 38/40\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.1335 - accuracy: 0.9964 - auc: 0.9997 - precision: 0.9969 - recall: 0.9959 - val_loss: 0.5297 - val_accuracy: 0.9314 - val_auc: 0.9591 - val_precision: 0.9497 - val_recall: 0.9119\n",
      "Epoch 39/40\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1263 - accuracy: 0.9962 - auc: 0.9995 - precision: 0.9967 - recall: 0.9957 - val_loss: 0.5809 - val_accuracy: 0.9272 - val_auc: 0.9556 - val_precision: 0.9470 - val_recall: 0.9060\n",
      "Epoch 40/40\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.1375 - accuracy: 0.9959 - auc: 0.9994 - precision: 0.9970 - recall: 0.9947 - val_loss: 0.5863 - val_accuracy: 0.9259 - val_auc: 0.9590 - val_precision: 0.9283 - val_recall: 0.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20dfac30340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=40, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3550e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "    \n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3550e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "284/284 [==============================] - 39s 106ms/step - loss: 0.1780 - accuracy: 0.9847 - auc: 0.9977 - precision: 0.9880 - recall: 0.9811 - val_loss: 0.4031 - val_accuracy: 0.9300 - val_auc: 0.9767 - val_precision: 0.9529 - val_recall: 0.9056\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.1972 - accuracy: 0.9884 - auc: 0.9987 - precision: 0.9914 - recall: 0.9850 - val_loss: 0.5241 - val_accuracy: 0.9334 - val_auc: 0.9682 - val_precision: 0.9422 - val_recall: 0.9242\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 29s 100ms/step - loss: 0.2106 - accuracy: 0.9890 - auc: 0.9986 - precision: 0.9919 - recall: 0.9859 - val_loss: 0.5094 - val_accuracy: 0.9324 - val_auc: 0.9700 - val_precision: 0.9441 - val_recall: 0.9201\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2335 - accuracy: 0.9886 - auc: 0.9985 - precision: 0.9911 - recall: 0.9857 - val_loss: 0.5172 - val_accuracy: 0.9294 - val_auc: 0.9684 - val_precision: 0.9262 - val_recall: 0.9341\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 28s 100ms/step - loss: 0.2452 - accuracy: 0.9873 - auc: 0.9983 - precision: 0.9894 - recall: 0.9848 - val_loss: 0.4680 - val_accuracy: 0.9331 - val_auc: 0.9732 - val_precision: 0.9452 - val_recall: 0.9203\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2005 - accuracy: 0.9906 - auc: 0.9990 - precision: 0.9926 - recall: 0.9885 - val_loss: 0.4485 - val_accuracy: 0.9314 - val_auc: 0.9720 - val_precision: 0.9572 - val_recall: 0.9040\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2136 - accuracy: 0.9890 - auc: 0.9987 - precision: 0.9918 - recall: 0.9860 - val_loss: 0.5058 - val_accuracy: 0.9339 - val_auc: 0.9721 - val_precision: 0.9427 - val_recall: 0.9247\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2228 - accuracy: 0.9897 - auc: 0.9989 - precision: 0.9918 - recall: 0.9875 - val_loss: 0.5175 - val_accuracy: 0.9325 - val_auc: 0.9698 - val_precision: 0.9315 - val_recall: 0.9345\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 29s 100ms/step - loss: 0.2135 - accuracy: 0.9901 - auc: 0.9989 - precision: 0.9923 - recall: 0.9878 - val_loss: 0.4840 - val_accuracy: 0.9321 - val_auc: 0.9706 - val_precision: 0.9583 - val_recall: 0.9042\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2078 - accuracy: 0.9894 - auc: 0.9990 - precision: 0.9915 - recall: 0.9870 - val_loss: 0.5189 - val_accuracy: 0.9312 - val_auc: 0.9678 - val_precision: 0.9296 - val_recall: 0.9339\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 29s 100ms/step - loss: 0.2099 - accuracy: 0.9892 - auc: 0.9988 - precision: 0.9916 - recall: 0.9865 - val_loss: 0.4664 - val_accuracy: 0.9338 - val_auc: 0.9709 - val_precision: 0.9555 - val_recall: 0.9106\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 29s 100ms/step - loss: 0.2506 - accuracy: 0.9874 - auc: 0.9983 - precision: 0.9915 - recall: 0.9831 - val_loss: 0.5704 - val_accuracy: 0.9293 - val_auc: 0.9635 - val_precision: 0.9178 - val_recall: 0.9440\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2266 - accuracy: 0.9895 - auc: 0.9987 - precision: 0.9915 - recall: 0.9872 - val_loss: 0.4937 - val_accuracy: 0.9340 - val_auc: 0.9698 - val_precision: 0.9530 - val_recall: 0.9137\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 28s 99ms/step - loss: 0.1962 - accuracy: 0.9905 - auc: 0.9990 - precision: 0.9923 - recall: 0.9886 - val_loss: 0.4831 - val_accuracy: 0.9328 - val_auc: 0.9683 - val_precision: 0.9380 - val_recall: 0.9275\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 28s 99ms/step - loss: 0.1886 - accuracy: 0.9906 - auc: 0.9990 - precision: 0.9929 - recall: 0.9880 - val_loss: 0.4917 - val_accuracy: 0.9323 - val_auc: 0.9699 - val_precision: 0.9588 - val_recall: 0.9042\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.1964 - accuracy: 0.9902 - auc: 0.9987 - precision: 0.9921 - recall: 0.9881 - val_loss: 0.5277 - val_accuracy: 0.9296 - val_auc: 0.9650 - val_precision: 0.9266 - val_recall: 0.9339\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.1990 - accuracy: 0.9907 - auc: 0.9990 - precision: 0.9926 - recall: 0.9886 - val_loss: 0.4982 - val_accuracy: 0.9345 - val_auc: 0.9671 - val_precision: 0.9514 - val_recall: 0.9165\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1998 - accuracy: 0.9906 - auc: 0.9993 - precision: 0.9924 - recall: 0.9886 - val_loss: 0.4672 - val_accuracy: 0.9346 - val_auc: 0.9716 - val_precision: 0.9352 - val_recall: 0.9348\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.2079 - accuracy: 0.9904 - auc: 0.9989 - precision: 0.9921 - recall: 0.9885 - val_loss: 0.5062 - val_accuracy: 0.9352 - val_auc: 0.9702 - val_precision: 0.9474 - val_recall: 0.9222\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 30s 107ms/step - loss: 0.2240 - accuracy: 0.9896 - auc: 0.9987 - precision: 0.9922 - recall: 0.9867 - val_loss: 0.4535 - val_accuracy: 0.9318 - val_auc: 0.9707 - val_precision: 0.9397 - val_recall: 0.9236\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.2042 - accuracy: 0.9901 - auc: 0.9990 - precision: 0.9925 - recall: 0.9875 - val_loss: 0.5204 - val_accuracy: 0.9354 - val_auc: 0.9664 - val_precision: 0.9427 - val_recall: 0.9280\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.2058 - accuracy: 0.9896 - auc: 0.9989 - precision: 0.9916 - recall: 0.9875 - val_loss: 0.4542 - val_accuracy: 0.9270 - val_auc: 0.9714 - val_precision: 0.9664 - val_recall: 0.8856\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.2133 - accuracy: 0.9901 - auc: 0.9988 - precision: 0.9921 - recall: 0.9880 - val_loss: 0.4761 - val_accuracy: 0.9347 - val_auc: 0.9696 - val_precision: 0.9440 - val_recall: 0.9251\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.1973 - accuracy: 0.9905 - auc: 0.9989 - precision: 0.9928 - recall: 0.9879 - val_loss: 0.5208 - val_accuracy: 0.9344 - val_auc: 0.9667 - val_precision: 0.9455 - val_recall: 0.9227\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 28s 100ms/step - loss: 0.2200 - accuracy: 0.9899 - auc: 0.9986 - precision: 0.9923 - recall: 0.9873 - val_loss: 0.4763 - val_accuracy: 0.9306 - val_auc: 0.9704 - val_precision: 0.9504 - val_recall: 0.9093\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.2071 - accuracy: 0.9901 - auc: 0.9991 - precision: 0.9926 - recall: 0.9875 - val_loss: 0.5005 - val_accuracy: 0.9320 - val_auc: 0.9717 - val_precision: 0.9331 - val_recall: 0.9315\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.2037 - accuracy: 0.9905 - auc: 0.9988 - precision: 0.9929 - recall: 0.9878 - val_loss: 0.5127 - val_accuracy: 0.9320 - val_auc: 0.9665 - val_precision: 0.9253 - val_recall: 0.9407\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 28s 99ms/step - loss: 0.1848 - accuracy: 0.9912 - auc: 0.9992 - precision: 0.9930 - recall: 0.9893 - val_loss: 0.4824 - val_accuracy: 0.9333 - val_auc: 0.9710 - val_precision: 0.9436 - val_recall: 0.9225\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 31s 108ms/step - loss: 0.2055 - accuracy: 0.9906 - auc: 0.9988 - precision: 0.9926 - recall: 0.9884 - val_loss: 0.5061 - val_accuracy: 0.9344 - val_auc: 0.9680 - val_precision: 0.9396 - val_recall: 0.9293\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.2049 - accuracy: 0.9901 - auc: 0.9987 - precision: 0.9924 - recall: 0.9876 - val_loss: 0.4896 - val_accuracy: 0.9328 - val_auc: 0.9699 - val_precision: 0.9458 - val_recall: 0.9190\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 30s 107ms/step - loss: 0.1890 - accuracy: 0.9911 - auc: 0.9991 - precision: 0.9932 - recall: 0.9888 - val_loss: 0.4458 - val_accuracy: 0.9313 - val_auc: 0.9743 - val_precision: 0.9361 - val_recall: 0.9266\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 30s 105ms/step - loss: 0.2084 - accuracy: 0.9909 - auc: 0.9990 - precision: 0.9929 - recall: 0.9886 - val_loss: 0.5420 - val_accuracy: 0.9309 - val_auc: 0.9659 - val_precision: 0.9341 - val_recall: 0.9280\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.2079 - accuracy: 0.9915 - auc: 0.9989 - precision: 0.9938 - recall: 0.9890 - val_loss: 0.5091 - val_accuracy: 0.9340 - val_auc: 0.9684 - val_precision: 0.9433 - val_recall: 0.9242\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1986 - accuracy: 0.9907 - auc: 0.9988 - precision: 0.9939 - recall: 0.9873 - val_loss: 0.4604 - val_accuracy: 0.9330 - val_auc: 0.9720 - val_precision: 0.9355 - val_recall: 0.9308\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1818 - accuracy: 0.9904 - auc: 0.9990 - precision: 0.9924 - recall: 0.9881 - val_loss: 0.5051 - val_accuracy: 0.9280 - val_auc: 0.9672 - val_precision: 0.9632 - val_recall: 0.8908\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.2192 - accuracy: 0.9898 - auc: 0.9988 - precision: 0.9923 - recall: 0.9871 - val_loss: 0.6017 - val_accuracy: 0.9297 - val_auc: 0.9633 - val_precision: 0.9209 - val_recall: 0.9409\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.2134 - accuracy: 0.9910 - auc: 0.9989 - precision: 0.9935 - recall: 0.9883 - val_loss: 0.4545 - val_accuracy: 0.9306 - val_auc: 0.9713 - val_precision: 0.9479 - val_recall: 0.9119\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.2087 - accuracy: 0.9906 - auc: 0.9990 - precision: 0.9927 - recall: 0.9882 - val_loss: 0.4653 - val_accuracy: 0.9328 - val_auc: 0.9743 - val_precision: 0.9480 - val_recall: 0.9165\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.2113 - accuracy: 0.9904 - auc: 0.9989 - precision: 0.9926 - recall: 0.9880 - val_loss: 0.5668 - val_accuracy: 0.9344 - val_auc: 0.9645 - val_precision: 0.9361 - val_recall: 0.9332\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1999 - accuracy: 0.9909 - auc: 0.9992 - precision: 0.9929 - recall: 0.9887 - val_loss: 0.5098 - val_accuracy: 0.9338 - val_auc: 0.9665 - val_precision: 0.9455 - val_recall: 0.9214\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1996 - accuracy: 0.9909 - auc: 0.9989 - precision: 0.9927 - recall: 0.9890 - val_loss: 0.4857 - val_accuracy: 0.9330 - val_auc: 0.9705 - val_precision: 0.9464 - val_recall: 0.9187\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.2128 - accuracy: 0.9907 - auc: 0.9991 - precision: 0.9927 - recall: 0.9885 - val_loss: 0.5177 - val_accuracy: 0.9266 - val_auc: 0.9666 - val_precision: 0.9127 - val_recall: 0.9442\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.1864 - accuracy: 0.9906 - auc: 0.9990 - precision: 0.9922 - recall: 0.9889 - val_loss: 0.5014 - val_accuracy: 0.9320 - val_auc: 0.9678 - val_precision: 0.9314 - val_recall: 0.9335\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1872 - accuracy: 0.9917 - auc: 0.9990 - precision: 0.9934 - recall: 0.9899 - val_loss: 0.4851 - val_accuracy: 0.9333 - val_auc: 0.9684 - val_precision: 0.9383 - val_recall: 0.9284\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.2144 - accuracy: 0.9898 - auc: 0.9987 - precision: 0.9924 - recall: 0.9868 - val_loss: 0.4950 - val_accuracy: 0.9317 - val_auc: 0.9709 - val_precision: 0.9276 - val_recall: 0.9372\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.1961 - accuracy: 0.9907 - auc: 0.9992 - precision: 0.9927 - recall: 0.9885 - val_loss: 0.4872 - val_accuracy: 0.9332 - val_auc: 0.9703 - val_precision: 0.9448 - val_recall: 0.9209\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.1914 - accuracy: 0.9916 - auc: 0.9990 - precision: 0.9934 - recall: 0.9896 - val_loss: 0.4476 - val_accuracy: 0.9330 - val_auc: 0.9737 - val_precision: 0.9344 - val_recall: 0.9321\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 30s 106ms/step - loss: 0.2005 - accuracy: 0.9902 - auc: 0.9988 - precision: 0.9922 - recall: 0.9881 - val_loss: 0.4505 - val_accuracy: 0.9325 - val_auc: 0.9750 - val_precision: 0.9484 - val_recall: 0.9157\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 31s 108ms/step - loss: 0.2181 - accuracy: 0.9903 - auc: 0.9988 - precision: 0.9921 - recall: 0.9883 - val_loss: 0.4303 - val_accuracy: 0.9311 - val_auc: 0.9766 - val_precision: 0.9464 - val_recall: 0.9148\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 31s 108ms/step - loss: 0.1962 - accuracy: 0.9915 - auc: 0.9989 - precision: 0.9933 - recall: 0.9896 - val_loss: 0.4584 - val_accuracy: 0.9324 - val_auc: 0.9699 - val_precision: 0.9285 - val_recall: 0.9378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15db49431c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3600e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "    \n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.05),\n",
    "              bias_regularizer=regularizers.l2(l=0.05))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.05),\n",
    "              bias_regularizer=regularizers.l2(l=0.05))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.05),\n",
    "              bias_regularizer=regularizers.l2(l=0.05))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3600e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "142/142 [==============================] - 38s 221ms/step - loss: 0.2341 - accuracy: 0.9874 - auc: 0.9989 - precision: 0.9901 - recall: 0.9843 - val_loss: 0.3936 - val_accuracy: 0.9343 - val_auc: 0.9773 - val_precision: 0.9415 - val_recall: 0.9269\n",
      "Epoch 2/50\n",
      "142/142 [==============================] - 28s 195ms/step - loss: 0.2056 - accuracy: 0.9897 - auc: 0.9991 - precision: 0.9923 - recall: 0.9869 - val_loss: 0.4440 - val_accuracy: 0.9308 - val_auc: 0.9758 - val_precision: 0.9347 - val_recall: 0.9271\n",
      "Epoch 3/50\n",
      "142/142 [==============================] - 29s 203ms/step - loss: 0.2490 - accuracy: 0.9883 - auc: 0.9988 - precision: 0.9909 - recall: 0.9854 - val_loss: 0.4539 - val_accuracy: 0.9317 - val_auc: 0.9731 - val_precision: 0.9358 - val_recall: 0.9277\n",
      "Epoch 4/50\n",
      "142/142 [==============================] - 28s 198ms/step - loss: 0.2300 - accuracy: 0.9892 - auc: 0.9989 - precision: 0.9918 - recall: 0.9863 - val_loss: 0.4682 - val_accuracy: 0.9313 - val_auc: 0.9739 - val_precision: 0.9400 - val_recall: 0.9222\n",
      "Epoch 5/50\n",
      "142/142 [==============================] - 30s 209ms/step - loss: 0.2491 - accuracy: 0.9884 - auc: 0.9989 - precision: 0.9916 - recall: 0.9850 - val_loss: 0.4918 - val_accuracy: 0.9290 - val_auc: 0.9747 - val_precision: 0.9289 - val_recall: 0.9299\n",
      "Epoch 6/50\n",
      "142/142 [==============================] - 28s 194ms/step - loss: 0.2580 - accuracy: 0.9887 - auc: 0.9987 - precision: 0.9913 - recall: 0.9860 - val_loss: 0.4642 - val_accuracy: 0.9317 - val_auc: 0.9751 - val_precision: 0.9282 - val_recall: 0.9365\n",
      "Epoch 7/50\n",
      "142/142 [==============================] - 28s 195ms/step - loss: 0.2331 - accuracy: 0.9901 - auc: 0.9991 - precision: 0.9924 - recall: 0.9876 - val_loss: 0.4370 - val_accuracy: 0.9334 - val_auc: 0.9758 - val_precision: 0.9450 - val_recall: 0.9212\n",
      "Epoch 8/50\n",
      "142/142 [==============================] - 28s 196ms/step - loss: 0.2674 - accuracy: 0.9881 - auc: 0.9988 - precision: 0.9914 - recall: 0.9845 - val_loss: 0.4898 - val_accuracy: 0.9311 - val_auc: 0.9747 - val_precision: 0.9253 - val_recall: 0.9387\n",
      "Epoch 9/50\n",
      "142/142 [==============================] - 28s 198ms/step - loss: 0.2691 - accuracy: 0.9887 - auc: 0.9987 - precision: 0.9908 - recall: 0.9863 - val_loss: 0.4972 - val_accuracy: 0.9321 - val_auc: 0.9776 - val_precision: 0.9437 - val_recall: 0.9198\n",
      "Epoch 10/50\n",
      "142/142 [==============================] - 28s 196ms/step - loss: 0.2777 - accuracy: 0.9893 - auc: 0.9988 - precision: 0.9919 - recall: 0.9864 - val_loss: 0.4783 - val_accuracy: 0.9313 - val_auc: 0.9757 - val_precision: 0.9442 - val_recall: 0.9176\n",
      "Epoch 11/50\n",
      "142/142 [==============================] - 28s 200ms/step - loss: 0.2794 - accuracy: 0.9886 - auc: 0.9987 - precision: 0.9916 - recall: 0.9853 - val_loss: 0.4626 - val_accuracy: 0.9329 - val_auc: 0.9779 - val_precision: 0.9369 - val_recall: 0.9291\n",
      "Epoch 12/50\n",
      "142/142 [==============================] - 29s 203ms/step - loss: 0.2465 - accuracy: 0.9903 - auc: 0.9990 - precision: 0.9928 - recall: 0.9875 - val_loss: 0.4787 - val_accuracy: 0.9302 - val_auc: 0.9737 - val_precision: 0.9381 - val_recall: 0.9220\n",
      "Epoch 13/50\n",
      "142/142 [==============================] - 29s 202ms/step - loss: 0.2752 - accuracy: 0.9890 - auc: 0.9991 - precision: 0.9913 - recall: 0.9863 - val_loss: 0.4775 - val_accuracy: 0.9314 - val_auc: 0.9739 - val_precision: 0.9478 - val_recall: 0.9139\n",
      "Epoch 14/50\n",
      "142/142 [==============================] - 29s 202ms/step - loss: 0.2459 - accuracy: 0.9902 - auc: 0.9990 - precision: 0.9922 - recall: 0.9880 - val_loss: 0.4724 - val_accuracy: 0.9329 - val_auc: 0.9743 - val_precision: 0.9344 - val_recall: 0.9319\n",
      "Epoch 15/50\n",
      "142/142 [==============================] - 28s 197ms/step - loss: 0.2712 - accuracy: 0.9892 - auc: 0.9989 - precision: 0.9919 - recall: 0.9861 - val_loss: 0.4964 - val_accuracy: 0.9342 - val_auc: 0.9730 - val_precision: 0.9457 - val_recall: 0.9220\n",
      "Epoch 16/50\n",
      "142/142 [==============================] - 28s 200ms/step - loss: 0.2923 - accuracy: 0.9885 - auc: 0.9989 - precision: 0.9908 - recall: 0.9860 - val_loss: 0.5160 - val_accuracy: 0.9318 - val_auc: 0.9704 - val_precision: 0.9383 - val_recall: 0.9251\n",
      "Epoch 17/50\n",
      "142/142 [==============================] - 28s 195ms/step - loss: 0.2879 - accuracy: 0.9886 - auc: 0.9988 - precision: 0.9910 - recall: 0.9860 - val_loss: 0.5092 - val_accuracy: 0.9330 - val_auc: 0.9763 - val_precision: 0.9446 - val_recall: 0.9207\n",
      "Epoch 18/50\n",
      "142/142 [==============================] - 28s 197ms/step - loss: 0.2724 - accuracy: 0.9891 - auc: 0.9990 - precision: 0.9917 - recall: 0.9862 - val_loss: 0.5120 - val_accuracy: 0.9313 - val_auc: 0.9717 - val_precision: 0.9619 - val_recall: 0.8990\n",
      "Epoch 19/50\n",
      "142/142 [==============================] - 29s 201ms/step - loss: 0.2596 - accuracy: 0.9890 - auc: 0.9989 - precision: 0.9917 - recall: 0.9860 - val_loss: 0.4892 - val_accuracy: 0.9285 - val_auc: 0.9726 - val_precision: 0.9150 - val_recall: 0.9455\n",
      "Epoch 20/50\n",
      "142/142 [==============================] - 29s 205ms/step - loss: 0.2412 - accuracy: 0.9896 - auc: 0.9991 - precision: 0.9913 - recall: 0.9878 - val_loss: 0.5112 - val_accuracy: 0.9302 - val_auc: 0.9731 - val_precision: 0.9248 - val_recall: 0.9374\n",
      "Epoch 21/50\n",
      "142/142 [==============================] - 28s 196ms/step - loss: 0.2506 - accuracy: 0.9886 - auc: 0.9986 - precision: 0.9909 - recall: 0.9860 - val_loss: 0.4645 - val_accuracy: 0.9330 - val_auc: 0.9769 - val_precision: 0.9400 - val_recall: 0.9258\n",
      "Epoch 22/50\n",
      " 87/142 [=================>............] - ETA: 10s - loss: 0.2626 - accuracy: 0.9884 - auc: 0.9987 - precision: 0.9917 - recall: 0.9848"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3650e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
