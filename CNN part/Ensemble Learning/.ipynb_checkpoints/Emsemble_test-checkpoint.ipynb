{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #%%\n",
    "# Emsemble Learning Test\n",
    "use 11 models to predict the test data by voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Dropout,Flatten,Dense,Activation,concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "X_test=pickle.load(open('X_test','rb'))/255.0\n",
    "y_test=pickle.load(open('y_test','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl=Input(shape=(128,128,1))\n",
    "\n",
    "    x=Conv2D(96,(3,3),padding=\"same\")(inputl)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "\n",
    "    x=Conv2D(72,(3,3),padding=\"same\")(x)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "\n",
    "    x1=Conv2D(72,(3,3),padding=\"same\")(x)\n",
    "    x1=Activation(\"relu\")(x1)\n",
    "    x1=MaxPooling2D(pool_size=(2,2))(x1)\n",
    "    x1=Dropout(0.3)(x1)\n",
    "    x2=Conv2D(32,(5,5),padding=\"same\")(x)\n",
    "    x2=Activation(\"relu\")(x2)\n",
    "    x2=MaxPooling2D(pool_size=(2,2))(x2)\n",
    "    x2=Dropout(.3)(x2)\n",
    "    x3=Conv2D(32,(7,7),padding=\"same\")(x)\n",
    "    x3=Activation(\"relu\")(x3)\n",
    "    x3=MaxPooling2D(pool_size=(2,2))(x3)\n",
    "    x3=Dropout(0.3)(x3)\n",
    "\n",
    "    x=concatenate([x1,x2,x3],axis=3)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "\n",
    "    x=Dense(84, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    outputl=Dense(1,activation=\"sigmoid\")(x)\n",
    "    model=Model(inputs=inputl,outputs=outputl)\n",
    "    opt= tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\",tf.keras.metrics.AUC(name='auc'),tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "model_f=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.load_weights('difker_3020e.h5')\n",
    "predict_result.append(model_f.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl=Input(shape=(128,128,1))\n",
    "\n",
    "    x=Conv2D(96,(3,3),padding=\"same\")(inputl)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x=Conv2D(72,(3,3),padding=\"same\")(x)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x1=Conv2D(72,(3,3),padding=\"same\")(x)\n",
    "    x1=Activation(\"relu\")(x1)\n",
    "    x1=MaxPooling2D(pool_size=(2,2))(x1)\n",
    "\n",
    "    x2=Conv2D(32,(5,5),padding=\"same\")(x)\n",
    "    x2=Activation(\"relu\")(x2)\n",
    "    x2=MaxPooling2D(pool_size=(2,2))(x2)\n",
    "\n",
    "    x3=Conv2D(32,(7,7),padding=\"same\")(x)\n",
    "    x3=Activation(\"relu\")(x3)\n",
    "    x3=MaxPooling2D(pool_size=(2,2))(x3)\n",
    "\n",
    "    x=concatenate([x1,x2,x3],axis=3)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "\n",
    "    x=Dense(84, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    outputl=Dense(1,activation=\"sigmoid\")(x)\n",
    "    model=Model(inputs=inputl,outputs=outputl)\n",
    "    opt= tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\",tf.keras.metrics.AUC(name='auc'),tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model=create_model()\n",
    "    model.load_weights('model'+str(i)+'.h5')\n",
    "    predict_result.append(model.predict(X_test))\n",
    "    print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result=np.array(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vote\n",
    "predict_result1=np.mean(predict_result,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result_df=pd.DataFrame(predict_result.reshape(11,9057))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9047</th>\n",
       "      <th>9048</th>\n",
       "      <th>9049</th>\n",
       "      <th>9050</th>\n",
       "      <th>9051</th>\n",
       "      <th>9052</th>\n",
       "      <th>9053</th>\n",
       "      <th>9054</th>\n",
       "      <th>9055</th>\n",
       "      <th>9056</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>2.747144e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.518153e-09</td>\n",
       "      <td>0.997982</td>\n",
       "      <td>3.163080e-08</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.106388</td>\n",
       "      <td>5.431856e-09</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>1.583856e-10</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>1.473525e-03</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>1.245846e-05</td>\n",
       "      <td>0.020802</td>\n",
       "      <td>1.360413e-04</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970967</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>6.975064e-04</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.045073</td>\n",
       "      <td>6.145109e-05</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.897809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.970452</td>\n",
       "      <td>0.959011</td>\n",
       "      <td>9.832104e-01</td>\n",
       "      <td>0.968867</td>\n",
       "      <td>9.661166e-01</td>\n",
       "      <td>0.690036</td>\n",
       "      <td>9.672221e-01</td>\n",
       "      <td>0.917117</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.904015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944325</td>\n",
       "      <td>0.948804</td>\n",
       "      <td>9.823104e-01</td>\n",
       "      <td>0.978829</td>\n",
       "      <td>0.881064</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>9.510401e-01</td>\n",
       "      <td>0.950574</td>\n",
       "      <td>0.961161</td>\n",
       "      <td>0.964612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>9.999905e-01</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>9.999934e-01</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>9.999433e-01</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>9.999952e-01</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>9.999545e-01</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>9.999417e-01</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>9.998720e-01</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>9.999391e-01</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>9.999641e-01</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999316e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999967e-01</td>\n",
       "      <td>0.999686</td>\n",
       "      <td>9.932065e-01</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.998027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>9.999990e-01</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>9.998761e-01</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>9.999107e-01</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>9.997993e-01</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.999733</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>9.999520e-01</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>9.999548e-01</td>\n",
       "      <td>0.999719</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.991731</td>\n",
       "      <td>0.986087</td>\n",
       "      <td>9.699954e-01</td>\n",
       "      <td>0.978799</td>\n",
       "      <td>9.427956e-01</td>\n",
       "      <td>0.924761</td>\n",
       "      <td>9.993334e-01</td>\n",
       "      <td>0.987249</td>\n",
       "      <td>0.974739</td>\n",
       "      <td>0.963710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946283</td>\n",
       "      <td>0.988903</td>\n",
       "      <td>9.848786e-01</td>\n",
       "      <td>0.988208</td>\n",
       "      <td>0.453673</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>9.656479e-01</td>\n",
       "      <td>0.827057</td>\n",
       "      <td>0.987870</td>\n",
       "      <td>0.988396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>9.999436e-01</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>9.999694e-01</td>\n",
       "      <td>0.999103</td>\n",
       "      <td>9.999149e-01</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>0.998834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>9.999944e-01</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>9.999918e-01</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.801219</td>\n",
       "      <td>0.785846</td>\n",
       "      <td>8.675820e-01</td>\n",
       "      <td>0.795796</td>\n",
       "      <td>8.098027e-01</td>\n",
       "      <td>0.719158</td>\n",
       "      <td>8.158931e-01</td>\n",
       "      <td>0.746311</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>0.857906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792479</td>\n",
       "      <td>0.750514</td>\n",
       "      <td>8.553532e-01</td>\n",
       "      <td>0.860499</td>\n",
       "      <td>0.780707</td>\n",
       "      <td>0.799271</td>\n",
       "      <td>8.059871e-01</td>\n",
       "      <td>0.819449</td>\n",
       "      <td>0.827431</td>\n",
       "      <td>0.831589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 9057 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1             2         3             4         5     \\\n",
       "0   0.006068  0.001199  2.747144e-07  1.000000  6.518153e-09  0.997982   \n",
       "1   0.999990  0.001102  1.473525e-03  0.999943  1.245846e-05  0.020802   \n",
       "2   0.970452  0.959011  9.832104e-01  0.968867  9.661166e-01  0.690036   \n",
       "3   0.999997  0.999999  9.999905e-01  0.999998  9.999934e-01  0.999873   \n",
       "4   0.999943  0.999960  9.999545e-01  0.999959  9.999417e-01  0.999908   \n",
       "5   0.999999  1.000000  9.999316e-01  1.000000  9.999967e-01  0.999686   \n",
       "6   0.999972  0.999981  9.998761e-01  0.999991  9.999107e-01  0.999584   \n",
       "7   0.991731  0.986087  9.699954e-01  0.978799  9.427956e-01  0.924761   \n",
       "8   1.000000  1.000000  9.999998e-01  1.000000  9.999996e-01  0.999998   \n",
       "9   0.999995  0.999993  9.999436e-01  0.999994  9.999694e-01  0.999103   \n",
       "10  0.801219  0.785846  8.675820e-01  0.795796  8.098027e-01  0.719158   \n",
       "\n",
       "            6         7         8         9     ...      9047      9048  \\\n",
       "0   3.163080e-08  0.000014  0.000988  0.999657  ...  0.002981  0.106388   \n",
       "1   1.360413e-04  0.001837  0.003620  0.999868  ...  0.970967  0.002050   \n",
       "2   9.672221e-01  0.917117  0.972028  0.904015  ...  0.944325  0.948804   \n",
       "3   9.999433e-01  0.999980  0.999949  0.999848  ...  0.999998  0.999997   \n",
       "4   9.998720e-01  0.999956  0.999870  0.999760  ...  0.999968  0.999937   \n",
       "5   9.932065e-01  0.999973  0.999723  0.998027  ...  1.000000  0.999969   \n",
       "6   9.997993e-01  0.999928  0.999733  0.998038  ...  0.999968  0.999962   \n",
       "7   9.993334e-01  0.987249  0.974739  0.963710  ...  0.946283  0.988903   \n",
       "8   9.999996e-01  1.000000  0.999999  0.999996  ...  1.000000  1.000000   \n",
       "9   9.999149e-01  0.999894  0.999827  0.998834  ...  0.999984  0.999978   \n",
       "10  8.158931e-01  0.746311  0.843527  0.857906  ...  0.792479  0.750514   \n",
       "\n",
       "            9049      9050      9051      9052          9053      9054  \\\n",
       "0   5.431856e-09  0.999998  0.000003  0.000889  1.583856e-10  0.999986   \n",
       "1   6.975064e-04  0.000997  0.000485  0.045073  6.145109e-05  0.999966   \n",
       "2   9.823104e-01  0.978829  0.881064  0.945100  9.510401e-01  0.950574   \n",
       "3   9.999952e-01  0.999983  0.999975  0.999964  9.999992e-01  0.999974   \n",
       "4   9.999391e-01  0.999922  0.999941  0.999881  9.999641e-01  0.999870   \n",
       "5   9.999990e-01  0.999994  0.999987  0.999776  9.999999e-01  0.999910   \n",
       "6   9.999520e-01  0.999921  0.999779  0.999858  9.999548e-01  0.999719   \n",
       "7   9.848786e-01  0.988208  0.453673  0.989301  9.656479e-01  0.827057   \n",
       "8   9.999999e-01  1.000000  0.999998  0.999999  1.000000e+00  0.999999   \n",
       "9   9.999944e-01  0.999946  0.999627  0.999743  9.999918e-01  0.999772   \n",
       "10  8.553532e-01  0.860499  0.780707  0.799271  8.059871e-01  0.819449   \n",
       "\n",
       "        9055      9056  \n",
       "0   0.000003  0.999921  \n",
       "1   0.000099  0.897809  \n",
       "2   0.961161  0.964612  \n",
       "3   0.999993  0.999999  \n",
       "4   0.999916  0.999975  \n",
       "5   0.999998  1.000000  \n",
       "6   0.999901  0.999975  \n",
       "7   0.987870  0.988396  \n",
       "8   1.000000  1.000000  \n",
       "9   0.999981  0.999995  \n",
       "10  0.827431  0.831589  \n",
       "\n",
       "[11 rows x 9057 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result1=np.where(predict_result1>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,predict_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 4504]\n",
      " [   0 4553]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
