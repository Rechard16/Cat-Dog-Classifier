{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Layer,add,Input,concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(\"X_train\", \"rb\"))\n",
    "y_train = pickle.load(open(\"y_train\", \"rb\"))\n",
    "X_test = pickle.load(open(\"X_test\", \"rb\"))\n",
    "y_test = pickle.load(open(\"y_test\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test/255.0\n",
    "X_train=X_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.002))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.002))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.002))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3410e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 37s 105ms/step - loss: 0.3402 - accuracy: 0.9460 - auc: 0.9865 - precision: 0.9546 - recall: 0.9354 - val_loss: 0.3994 - val_accuracy: 0.9302 - val_auc: 0.9830 - val_precision: 0.9580 - val_recall: 0.9007\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.3463 - accuracy: 0.9550 - auc: 0.9911 - precision: 0.9612 - recall: 0.9473 - val_loss: 0.3899 - val_accuracy: 0.9355 - val_auc: 0.9835 - val_precision: 0.9563 - val_recall: 0.9135\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3433 - accuracy: 0.9555 - auc: 0.9908 - precision: 0.9606 - recall: 0.9491 - val_loss: 0.3902 - val_accuracy: 0.9340 - val_auc: 0.9834 - val_precision: 0.9530 - val_recall: 0.9137\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.3396 - accuracy: 0.9578 - auc: 0.9915 - precision: 0.9663 - recall: 0.9479 - val_loss: 0.3822 - val_accuracy: 0.9367 - val_auc: 0.9840 - val_precision: 0.9498 - val_recall: 0.9229\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3285 - accuracy: 0.9583 - auc: 0.9919 - precision: 0.9647 - recall: 0.9506 - val_loss: 0.3949 - val_accuracy: 0.9276 - val_auc: 0.9836 - val_precision: 0.9629 - val_recall: 0.8902\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3212 - accuracy: 0.9581 - auc: 0.9921 - precision: 0.9638 - recall: 0.9511 - val_loss: 0.3731 - val_accuracy: 0.9334 - val_auc: 0.9841 - val_precision: 0.9563 - val_recall: 0.9091\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3165 - accuracy: 0.9564 - auc: 0.9912 - precision: 0.9638 - recall: 0.9476 - val_loss: 0.3538 - val_accuracy: 0.9345 - val_auc: 0.9839 - val_precision: 0.9560 - val_recall: 0.9117\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.2973 - accuracy: 0.9586 - auc: 0.9923 - precision: 0.9649 - recall: 0.9510 - val_loss: 0.3644 - val_accuracy: 0.9355 - val_auc: 0.9829 - val_precision: 0.9415 - val_recall: 0.9295\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.2968 - accuracy: 0.9589 - auc: 0.9923 - precision: 0.9647 - recall: 0.9517 - val_loss: 0.3699 - val_accuracy: 0.9328 - val_auc: 0.9831 - val_precision: 0.9540 - val_recall: 0.9102\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3099 - accuracy: 0.9568 - auc: 0.9916 - precision: 0.9633 - recall: 0.9489 - val_loss: 0.3871 - val_accuracy: 0.9336 - val_auc: 0.9817 - val_precision: 0.9589 - val_recall: 0.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cd7315f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3420e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.005))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.005))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.005))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3420e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3846 - accuracy: 0.9484 - auc: 0.9877 - precision: 0.9546 - recall: 0.9405 - val_loss: 0.3849 - val_accuracy: 0.9363 - val_auc: 0.9836 - val_precision: 0.9494 - val_recall: 0.9225\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3373 - accuracy: 0.9510 - auc: 0.9901 - precision: 0.9556 - recall: 0.9449 - val_loss: 0.3885 - val_accuracy: 0.9351 - val_auc: 0.9835 - val_precision: 0.9573 - val_recall: 0.9115\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3499 - accuracy: 0.9505 - auc: 0.9894 - precision: 0.9563 - recall: 0.9432 - val_loss: 0.4077 - val_accuracy: 0.9319 - val_auc: 0.9822 - val_precision: 0.9551 - val_recall: 0.9071\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3365 - accuracy: 0.9541 - auc: 0.9903 - precision: 0.9591 - recall: 0.9477 - val_loss: 0.3887 - val_accuracy: 0.9367 - val_auc: 0.9835 - val_precision: 0.9494 - val_recall: 0.9233\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3366 - accuracy: 0.9526 - auc: 0.9903 - precision: 0.9582 - recall: 0.9456 - val_loss: 0.3625 - val_accuracy: 0.9351 - val_auc: 0.9832 - val_precision: 0.9534 - val_recall: 0.9157\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.3232 - accuracy: 0.9535 - auc: 0.9905 - precision: 0.9569 - recall: 0.9488 - val_loss: 0.3814 - val_accuracy: 0.9298 - val_auc: 0.9831 - val_precision: 0.9102 - val_recall: 0.9545\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3600 - accuracy: 0.9518 - auc: 0.9895 - precision: 0.9524 - recall: 0.9502 - val_loss: 0.3842 - val_accuracy: 0.9328 - val_auc: 0.9824 - val_precision: 0.9523 - val_recall: 0.9119\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3359 - accuracy: 0.9536 - auc: 0.9902 - precision: 0.9574 - recall: 0.9486 - val_loss: 0.3677 - val_accuracy: 0.9320 - val_auc: 0.9836 - val_precision: 0.9479 - val_recall: 0.9150\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3045 - accuracy: 0.9565 - auc: 0.9913 - precision: 0.9592 - recall: 0.9527 - val_loss: 0.3754 - val_accuracy: 0.9371 - val_auc: 0.9832 - val_precision: 0.9537 - val_recall: 0.9194\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3068 - accuracy: 0.9559 - auc: 0.9907 - precision: 0.9598 - recall: 0.9508 - val_loss: 0.3405 - val_accuracy: 0.9363 - val_auc: 0.9831 - val_precision: 0.9404 - val_recall: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261f0c45b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3430e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3430e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "284/284 [==============================] - 30s 100ms/step - loss: 0.3600 - accuracy: 0.9513 - auc: 0.9892 - precision: 0.9536 - recall: 0.9478 - val_loss: 0.4305 - val_accuracy: 0.9334 - val_auc: 0.9822 - val_precision: 0.9360 - val_recall: 0.9313\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 28s 100ms/step - loss: 0.3521 - accuracy: 0.9519 - auc: 0.9891 - precision: 0.9571 - recall: 0.9452 - val_loss: 0.3971 - val_accuracy: 0.9319 - val_auc: 0.9826 - val_precision: 0.9558 - val_recall: 0.9064\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3796 - accuracy: 0.9514 - auc: 0.9884 - precision: 0.9550 - recall: 0.9465 - val_loss: 0.3929 - val_accuracy: 0.9362 - val_auc: 0.9828 - val_precision: 0.9441 - val_recall: 0.9280\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 29s 104ms/step - loss: 0.3567 - accuracy: 0.9524 - auc: 0.9897 - precision: 0.9568 - recall: 0.9466 - val_loss: 0.4033 - val_accuracy: 0.9303 - val_auc: 0.9832 - val_precision: 0.9687 - val_recall: 0.8902\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 30s 104ms/step - loss: 0.3705 - accuracy: 0.9513 - auc: 0.9886 - precision: 0.9587 - recall: 0.9422 - val_loss: 0.3937 - val_accuracy: 0.9372 - val_auc: 0.9829 - val_precision: 0.9456 - val_recall: 0.9284\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 30s 105ms/step - loss: 0.3557 - accuracy: 0.9534 - auc: 0.9895 - precision: 0.9593 - recall: 0.9460 - val_loss: 0.4096 - val_accuracy: 0.9335 - val_auc: 0.9815 - val_precision: 0.9372 - val_recall: 0.9302\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3660 - accuracy: 0.9520 - auc: 0.9890 - precision: 0.9580 - recall: 0.9446 - val_loss: 0.3892 - val_accuracy: 0.9328 - val_auc: 0.9814 - val_precision: 0.9388 - val_recall: 0.9266\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 29s 102ms/step - loss: 0.3566 - accuracy: 0.9528 - auc: 0.9895 - precision: 0.9584 - recall: 0.9458 - val_loss: 0.4292 - val_accuracy: 0.9315 - val_auc: 0.9822 - val_precision: 0.9243 - val_recall: 0.9409\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 29s 103ms/step - loss: 0.3713 - accuracy: 0.9524 - auc: 0.9894 - precision: 0.9583 - recall: 0.9451 - val_loss: 0.4011 - val_accuracy: 0.9338 - val_auc: 0.9823 - val_precision: 0.9530 - val_recall: 0.9132\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 29s 101ms/step - loss: 0.3675 - accuracy: 0.9527 - auc: 0.9899 - precision: 0.9581 - recall: 0.9460 - val_loss: 0.4104 - val_accuracy: 0.9326 - val_auc: 0.9811 - val_precision: 0.9292 - val_recall: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26241621610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3440e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    #x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    #x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    #x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3440e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "284/284 [==============================] - 32s 95ms/step - loss: 0.1284 - accuracy: 0.9881 - auc: 0.9989 - precision: 0.9875 - recall: 0.9885 - val_loss: 0.3683 - val_accuracy: 0.9276 - val_auc: 0.9746 - val_precision: 0.9304 - val_recall: 0.9251\n",
      "Epoch 2/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.1166 - accuracy: 0.9910 - auc: 0.9994 - precision: 0.9900 - recall: 0.9919 - val_loss: 0.3403 - val_accuracy: 0.9303 - val_auc: 0.9721 - val_precision: 0.9335 - val_recall: 0.9275\n",
      "Epoch 3/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.1058 - accuracy: 0.9918 - auc: 0.9995 - precision: 0.9907 - recall: 0.9928 - val_loss: 0.3300 - val_accuracy: 0.9309 - val_auc: 0.9738 - val_precision: 0.9494 - val_recall: 0.9110\n",
      "Epoch 4/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.1028 - accuracy: 0.9933 - auc: 0.9995 - precision: 0.9925 - recall: 0.9941 - val_loss: 0.4142 - val_accuracy: 0.9302 - val_auc: 0.9659 - val_precision: 0.9465 - val_recall: 0.9128\n",
      "Epoch 5/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.1097 - accuracy: 0.9938 - auc: 0.9996 - precision: 0.9939 - recall: 0.9936 - val_loss: 0.3643 - val_accuracy: 0.9267 - val_auc: 0.9703 - val_precision: 0.9203 - val_recall: 0.9352\n",
      "Epoch 6/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0747 - accuracy: 0.9954 - auc: 0.9998 - precision: 0.9952 - recall: 0.9954 - val_loss: 0.3339 - val_accuracy: 0.9265 - val_auc: 0.9721 - val_precision: 0.9147 - val_recall: 0.9416\n",
      "Epoch 7/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0874 - accuracy: 0.9943 - auc: 0.9997 - precision: 0.9938 - recall: 0.9948 - val_loss: 0.3579 - val_accuracy: 0.9304 - val_auc: 0.9724 - val_precision: 0.9346 - val_recall: 0.9264\n",
      "Epoch 8/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0740 - accuracy: 0.9956 - auc: 0.9998 - precision: 0.9953 - recall: 0.9959 - val_loss: 0.4261 - val_accuracy: 0.9292 - val_auc: 0.9633 - val_precision: 0.9245 - val_recall: 0.9356\n",
      "Epoch 9/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0719 - accuracy: 0.9959 - auc: 0.9998 - precision: 0.9961 - recall: 0.9956 - val_loss: 0.3950 - val_accuracy: 0.9308 - val_auc: 0.9668 - val_precision: 0.9517 - val_recall: 0.9084\n",
      "Epoch 10/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0702 - accuracy: 0.9964 - auc: 0.9998 - precision: 0.9963 - recall: 0.9964 - val_loss: 0.3721 - val_accuracy: 0.9307 - val_auc: 0.9700 - val_precision: 0.9421 - val_recall: 0.9185\n",
      "Epoch 11/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0926 - accuracy: 0.9953 - auc: 0.9996 - precision: 0.9953 - recall: 0.9952 - val_loss: 0.3868 - val_accuracy: 0.9332 - val_auc: 0.9685 - val_precision: 0.9375 - val_recall: 0.9291\n",
      "Epoch 12/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0586 - accuracy: 0.9970 - auc: 0.9999 - precision: 0.9970 - recall: 0.9969 - val_loss: 0.4054 - val_accuracy: 0.9298 - val_auc: 0.9667 - val_precision: 0.9388 - val_recall: 0.9203\n",
      "Epoch 13/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0696 - accuracy: 0.9962 - auc: 0.9998 - precision: 0.9959 - recall: 0.9964 - val_loss: 0.4026 - val_accuracy: 0.9285 - val_auc: 0.9670 - val_precision: 0.9500 - val_recall: 0.9053\n",
      "Epoch 14/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0565 - accuracy: 0.9974 - auc: 0.9998 - precision: 0.9974 - recall: 0.9973 - val_loss: 0.4267 - val_accuracy: 0.9272 - val_auc: 0.9636 - val_precision: 0.9503 - val_recall: 0.9025\n",
      "Epoch 15/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0832 - accuracy: 0.9956 - auc: 0.9998 - precision: 0.9954 - recall: 0.9957 - val_loss: 0.4393 - val_accuracy: 0.9306 - val_auc: 0.9642 - val_precision: 0.9397 - val_recall: 0.9209\n",
      "Epoch 16/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0690 - accuracy: 0.9970 - auc: 0.9998 - precision: 0.9972 - recall: 0.9968 - val_loss: 0.3613 - val_accuracy: 0.9304 - val_auc: 0.9685 - val_precision: 0.9451 - val_recall: 0.9148\n",
      "Epoch 17/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0670 - accuracy: 0.9972 - auc: 0.9997 - precision: 0.9970 - recall: 0.9974 - val_loss: 0.3641 - val_accuracy: 0.9318 - val_auc: 0.9683 - val_precision: 0.9572 - val_recall: 0.9047\n",
      "Epoch 18/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0769 - accuracy: 0.9960 - auc: 0.9997 - precision: 0.9959 - recall: 0.9960 - val_loss: 0.4391 - val_accuracy: 0.9261 - val_auc: 0.9624 - val_precision: 0.9354 - val_recall: 0.9163\n",
      "Epoch 19/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0678 - accuracy: 0.9965 - auc: 0.9997 - precision: 0.9963 - recall: 0.9968 - val_loss: 0.3955 - val_accuracy: 0.9267 - val_auc: 0.9673 - val_precision: 0.9369 - val_recall: 0.9159\n",
      "Epoch 20/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0564 - accuracy: 0.9971 - auc: 0.9998 - precision: 0.9967 - recall: 0.9975 - val_loss: 0.4182 - val_accuracy: 0.9300 - val_auc: 0.9618 - val_precision: 0.9361 - val_recall: 0.9238\n",
      "Epoch 21/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0553 - accuracy: 0.9979 - auc: 0.9999 - precision: 0.9975 - recall: 0.9982 - val_loss: 0.4960 - val_accuracy: 0.9283 - val_auc: 0.9564 - val_precision: 0.9561 - val_recall: 0.8987\n",
      "Epoch 22/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0620 - accuracy: 0.9966 - auc: 0.9998 - precision: 0.9958 - recall: 0.9973 - val_loss: 0.4301 - val_accuracy: 0.9288 - val_auc: 0.9633 - val_precision: 0.9439 - val_recall: 0.9126\n",
      "Epoch 23/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0703 - accuracy: 0.9968 - auc: 0.9997 - precision: 0.9962 - recall: 0.9973 - val_loss: 0.4042 - val_accuracy: 0.9267 - val_auc: 0.9635 - val_precision: 0.9271 - val_recall: 0.9271\n",
      "Epoch 24/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0523 - accuracy: 0.9976 - auc: 0.9998 - precision: 0.9970 - recall: 0.9981 - val_loss: 0.4111 - val_accuracy: 0.9246 - val_auc: 0.9613 - val_precision: 0.9181 - val_recall: 0.9332\n",
      "Epoch 25/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0689 - accuracy: 0.9970 - auc: 0.9997 - precision: 0.9967 - recall: 0.9972 - val_loss: 0.3842 - val_accuracy: 0.9285 - val_auc: 0.9675 - val_precision: 0.9307 - val_recall: 0.9266\n",
      "Epoch 26/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0628 - accuracy: 0.9972 - auc: 0.9998 - precision: 0.9969 - recall: 0.9974 - val_loss: 0.4035 - val_accuracy: 0.9275 - val_auc: 0.9642 - val_precision: 0.9186 - val_recall: 0.9389\n",
      "Epoch 27/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0724 - accuracy: 0.9966 - auc: 0.9998 - precision: 0.9960 - recall: 0.9972 - val_loss: 0.4613 - val_accuracy: 0.9257 - val_auc: 0.9575 - val_precision: 0.9462 - val_recall: 0.9036\n",
      "Epoch 28/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0527 - accuracy: 0.9979 - auc: 0.9999 - precision: 0.9975 - recall: 0.9983 - val_loss: 0.4276 - val_accuracy: 0.9310 - val_auc: 0.9583 - val_precision: 0.9400 - val_recall: 0.9216\n",
      "Epoch 29/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0497 - accuracy: 0.9977 - auc: 0.9998 - precision: 0.9974 - recall: 0.9978 - val_loss: 0.3565 - val_accuracy: 0.9257 - val_auc: 0.9675 - val_precision: 0.9305 - val_recall: 0.9209\n",
      "Epoch 30/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0484 - accuracy: 0.9972 - auc: 0.9998 - precision: 0.9968 - recall: 0.9975 - val_loss: 0.4460 - val_accuracy: 0.9213 - val_auc: 0.9606 - val_precision: 0.9017 - val_recall: 0.9466\n",
      "Epoch 31/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0564 - accuracy: 0.9973 - auc: 0.9999 - precision: 0.9966 - recall: 0.9979 - val_loss: 0.4485 - val_accuracy: 0.9298 - val_auc: 0.9604 - val_precision: 0.9485 - val_recall: 0.9097\n",
      "Epoch 32/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0517 - accuracy: 0.9976 - auc: 0.9998 - precision: 0.9970 - recall: 0.9982 - val_loss: 0.3945 - val_accuracy: 0.9282 - val_auc: 0.9628 - val_precision: 0.9336 - val_recall: 0.9229\n",
      "Epoch 33/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0597 - accuracy: 0.9970 - auc: 0.9999 - precision: 0.9964 - recall: 0.9975 - val_loss: 0.4214 - val_accuracy: 0.9285 - val_auc: 0.9622 - val_precision: 0.9218 - val_recall: 0.9372\n",
      "Epoch 34/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0704 - accuracy: 0.9979 - auc: 0.9998 - precision: 0.9974 - recall: 0.9983 - val_loss: 0.4515 - val_accuracy: 0.9294 - val_auc: 0.9597 - val_precision: 0.9446 - val_recall: 0.9132\n",
      "Epoch 35/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0839 - accuracy: 0.9970 - auc: 0.9997 - precision: 0.9962 - recall: 0.9977 - val_loss: 0.5007 - val_accuracy: 0.9220 - val_auc: 0.9558 - val_precision: 0.9116 - val_recall: 0.9356\n",
      "Epoch 36/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0757 - accuracy: 0.9964 - auc: 0.9997 - precision: 0.9953 - recall: 0.9974 - val_loss: 0.5257 - val_accuracy: 0.9298 - val_auc: 0.9578 - val_precision: 0.9430 - val_recall: 0.9157\n",
      "Epoch 37/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0665 - accuracy: 0.9971 - auc: 0.9998 - precision: 0.9959 - recall: 0.9982 - val_loss: 0.3975 - val_accuracy: 0.9251 - val_auc: 0.9605 - val_precision: 0.9301 - val_recall: 0.9203\n",
      "Epoch 38/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0574 - accuracy: 0.9977 - auc: 0.9997 - precision: 0.9973 - recall: 0.9981 - val_loss: 0.4444 - val_accuracy: 0.9249 - val_auc: 0.9600 - val_precision: 0.9029 - val_recall: 0.9532\n",
      "Epoch 39/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0477 - accuracy: 0.9977 - auc: 0.9999 - precision: 0.9972 - recall: 0.9982 - val_loss: 0.3963 - val_accuracy: 0.9290 - val_auc: 0.9616 - val_precision: 0.9254 - val_recall: 0.9341\n",
      "Epoch 40/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0407 - accuracy: 0.9983 - auc: 0.9999 - precision: 0.9978 - recall: 0.9988 - val_loss: 0.4349 - val_accuracy: 0.9296 - val_auc: 0.9575 - val_precision: 0.9318 - val_recall: 0.9277\n",
      "Epoch 41/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0390 - accuracy: 0.9981 - auc: 0.9999 - precision: 0.9977 - recall: 0.9985 - val_loss: 0.3943 - val_accuracy: 0.9262 - val_auc: 0.9597 - val_precision: 0.9550 - val_recall: 0.8955\n",
      "Epoch 42/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0740 - accuracy: 0.9966 - auc: 0.9997 - precision: 0.9958 - recall: 0.9973 - val_loss: 0.4347 - val_accuracy: 0.9302 - val_auc: 0.9597 - val_precision: 0.9335 - val_recall: 0.9273\n",
      "Epoch 43/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0584 - accuracy: 0.9976 - auc: 0.9998 - precision: 0.9969 - recall: 0.9983 - val_loss: 0.4074 - val_accuracy: 0.9291 - val_auc: 0.9614 - val_precision: 0.9243 - val_recall: 0.9356\n",
      "Epoch 44/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0386 - accuracy: 0.9987 - auc: 0.9999 - precision: 0.9983 - recall: 0.9991 - val_loss: 0.4014 - val_accuracy: 0.9240 - val_auc: 0.9616 - val_precision: 0.9111 - val_recall: 0.9407\n",
      "Epoch 45/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0638 - accuracy: 0.9973 - auc: 0.9996 - precision: 0.9966 - recall: 0.9980 - val_loss: 0.3987 - val_accuracy: 0.9209 - val_auc: 0.9684 - val_precision: 0.9011 - val_recall: 0.9466\n",
      "Epoch 46/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0930 - accuracy: 0.9967 - auc: 0.9998 - precision: 0.9961 - recall: 0.9973 - val_loss: 0.4675 - val_accuracy: 0.9251 - val_auc: 0.9586 - val_precision: 0.9213 - val_recall: 0.9306\n",
      "Epoch 47/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0479 - accuracy: 0.9985 - auc: 0.9999 - precision: 0.9981 - recall: 0.9989 - val_loss: 0.5093 - val_accuracy: 0.9287 - val_auc: 0.9519 - val_precision: 0.9529 - val_recall: 0.9027\n",
      "Epoch 48/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0788 - accuracy: 0.9970 - auc: 0.9997 - precision: 0.9964 - recall: 0.9976 - val_loss: 0.4153 - val_accuracy: 0.9293 - val_auc: 0.9621 - val_precision: 0.9267 - val_recall: 0.9332\n",
      "Epoch 49/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0687 - accuracy: 0.9977 - auc: 0.9997 - precision: 0.9973 - recall: 0.9980 - val_loss: 0.3916 - val_accuracy: 0.9312 - val_auc: 0.9649 - val_precision: 0.9336 - val_recall: 0.9293\n",
      "Epoch 50/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0453 - accuracy: 0.9982 - auc: 0.9999 - precision: 0.9976 - recall: 0.9988 - val_loss: 0.4242 - val_accuracy: 0.9298 - val_auc: 0.9593 - val_precision: 0.9268 - val_recall: 0.9341\n",
      "Epoch 51/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0413 - accuracy: 0.9977 - auc: 0.9998 - precision: 0.9969 - recall: 0.9984 - val_loss: 0.4696 - val_accuracy: 0.9261 - val_auc: 0.9566 - val_precision: 0.9225 - val_recall: 0.9313\n",
      "Epoch 52/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0830 - accuracy: 0.9967 - auc: 0.9996 - precision: 0.9958 - recall: 0.9976 - val_loss: 0.4344 - val_accuracy: 0.9246 - val_auc: 0.9670 - val_precision: 0.9352 - val_recall: 0.9132\n",
      "Epoch 53/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0788 - accuracy: 0.9977 - auc: 0.9997 - precision: 0.9974 - recall: 0.9979 - val_loss: 0.5099 - val_accuracy: 0.9320 - val_auc: 0.9546 - val_precision: 0.9419 - val_recall: 0.9216\n",
      "Epoch 54/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0442 - accuracy: 0.9987 - auc: 0.9998 - precision: 0.9985 - recall: 0.9989 - val_loss: 0.4578 - val_accuracy: 0.9290 - val_auc: 0.9547 - val_precision: 0.9488 - val_recall: 0.9078\n",
      "Epoch 55/60\n",
      "284/284 [==============================] - 24s 86ms/step - loss: 0.0433 - accuracy: 0.9983 - auc: 0.9998 - precision: 0.9978 - recall: 0.9989 - val_loss: 0.4302 - val_accuracy: 0.9301 - val_auc: 0.9562 - val_precision: 0.9438 - val_recall: 0.9154\n",
      "Epoch 56/60\n",
      "284/284 [==============================] - 25s 89ms/step - loss: 0.0530 - accuracy: 0.9980 - auc: 0.9998 - precision: 0.9977 - recall: 0.9983 - val_loss: 0.5033 - val_accuracy: 0.9244 - val_auc: 0.9554 - val_precision: 0.9405 - val_recall: 0.9069\n",
      "Epoch 57/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0513 - accuracy: 0.9984 - auc: 0.9998 - precision: 0.9981 - recall: 0.9987 - val_loss: 0.3863 - val_accuracy: 0.9261 - val_auc: 0.9633 - val_precision: 0.9308 - val_recall: 0.9216\n",
      "Epoch 58/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0871 - accuracy: 0.9965 - auc: 0.9995 - precision: 0.9958 - recall: 0.9972 - val_loss: 0.4840 - val_accuracy: 0.9288 - val_auc: 0.9603 - val_precision: 0.9377 - val_recall: 0.9194\n",
      "Epoch 59/60\n",
      "284/284 [==============================] - 25s 87ms/step - loss: 0.0591 - accuracy: 0.9982 - auc: 0.9998 - precision: 0.9979 - recall: 0.9985 - val_loss: 0.3842 - val_accuracy: 0.9301 - val_auc: 0.9669 - val_precision: 0.9246 - val_recall: 0.9374\n",
      "Epoch 60/60\n",
      "284/284 [==============================] - 25s 88ms/step - loss: 0.0750 - accuracy: 0.9974 - auc: 0.9996 - precision: 0.9972 - recall: 0.9976 - val_loss: 0.4888 - val_accuracy: 0.9309 - val_auc: 0.9560 - val_precision: 0.9322 - val_recall: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x279688f2640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=60, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3500e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3500e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1133/1133 [==============================] - 37s 29ms/step - loss: 0.1343 - accuracy: 0.9915 - auc: 0.9987 - precision: 0.9912 - recall: 0.9917 - val_loss: 0.3978 - val_accuracy: 0.9246 - val_auc: 0.9661 - val_precision: 0.9283 - val_recall: 0.9212\n",
      "Epoch 2/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.0900 - accuracy: 0.9962 - auc: 0.9996 - precision: 0.9955 - recall: 0.9968 - val_loss: 0.4159 - val_accuracy: 0.9258 - val_auc: 0.9658 - val_precision: 0.9144 - val_recall: 0.9405\n",
      "Epoch 3/10\n",
      "1133/1133 [==============================] - 31s 28ms/step - loss: 0.1053 - accuracy: 0.9959 - auc: 0.9994 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.4510 - val_accuracy: 0.9243 - val_auc: 0.9634 - val_precision: 0.9279 - val_recall: 0.9209\n",
      "Epoch 4/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.1088 - accuracy: 0.9950 - auc: 0.9994 - precision: 0.9948 - recall: 0.9952 - val_loss: 0.4248 - val_accuracy: 0.9298 - val_auc: 0.9622 - val_precision: 0.9300 - val_recall: 0.9304\n",
      "Epoch 5/10\n",
      "1133/1133 [==============================] - 32s 28ms/step - loss: 0.0965 - accuracy: 0.9951 - auc: 0.9994 - precision: 0.9947 - recall: 0.9954 - val_loss: 0.4683 - val_accuracy: 0.9257 - val_auc: 0.9618 - val_precision: 0.9247 - val_recall: 0.9277\n",
      "Epoch 6/10\n",
      "1133/1133 [==============================] - 31s 28ms/step - loss: 0.0924 - accuracy: 0.9961 - auc: 0.9995 - precision: 0.9957 - recall: 0.9964 - val_loss: 0.6560 - val_accuracy: 0.9267 - val_auc: 0.9574 - val_precision: 0.9232 - val_recall: 0.9317\n",
      "Epoch 7/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.1270 - accuracy: 0.9950 - auc: 0.9993 - precision: 0.9945 - recall: 0.9954 - val_loss: 0.5070 - val_accuracy: 0.9243 - val_auc: 0.9591 - val_precision: 0.9168 - val_recall: 0.9341\n",
      "Epoch 8/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.1179 - accuracy: 0.9945 - auc: 0.9995 - precision: 0.9941 - recall: 0.9949 - val_loss: 0.4286 - val_accuracy: 0.9229 - val_auc: 0.9636 - val_precision: 0.9079 - val_recall: 0.9422\n",
      "Epoch 9/10\n",
      "1133/1133 [==============================] - 31s 27ms/step - loss: 0.0880 - accuracy: 0.9965 - auc: 0.9998 - precision: 0.9962 - recall: 0.9969 - val_loss: 0.6113 - val_accuracy: 0.9300 - val_auc: 0.9528 - val_precision: 0.9499 - val_recall: 0.9086\n",
      "Epoch 10/10\n",
      "1133/1133 [==============================] - 29s 25ms/step - loss: 0.0973 - accuracy: 0.9953 - auc: 0.9994 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.5143 - val_accuracy: 0.9170 - val_auc: 0.9597 - val_precision: 0.8949 - val_recall: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8c3263160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3510e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl = Input(shape=(128, 128, 1))\n",
    "\n",
    "    x = Conv2D(96, (3, 3), padding=\"same\")(inputl)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "\n",
    "    x1 = Conv2D(72, (3, 3), padding=\"same\")(x)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    #x1 = Dropout(0.3)(x1)\n",
    "    x2 = Conv2D(32, (5, 5), padding=\"same\")(x)\n",
    "    x2 = Activation(\"relu\")(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    #x2 = Dropout(.3)(x2)\n",
    "    x3 = Conv2D(32, (7, 7), padding=\"same\")(x)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    #x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    x = concatenate([x1, x2, x3], axis=3)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(84, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(l=0.01),\n",
    "              bias_regularizer=regularizers.l2(l=0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputl = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputl, outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"difker_3510e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=40, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"difker_3550e.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
