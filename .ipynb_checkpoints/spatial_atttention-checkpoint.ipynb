{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= pickle.load(open(\"X_train\",\"rb\"))\n",
    "y_train= pickle.load(open(\"y_train\",\"rb\"))\n",
    "X_test= pickle.load(open(\"X_test\",\"rb\"))\n",
    "y_test= pickle.load(open(\"y_test\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9057, 128, 128, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel_dim = int(input_feature.shape[-1])\n",
    "    shared_layer_one = Dense(channel_dim//ratio, activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel_dim, kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = Reshape((1,1,channel_dim))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel_dim))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "    return Multiply()([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    cbam_feature = Conv2D(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=1,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          use_bias=False)(concat)\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "    return Multiply()([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputl=Input(shape=(128,128,1))\n",
    "\n",
    "    x=Conv2D(96,(3,3),padding=\"same\")(inputl)\n",
    "    x=Dropout(0.3)(x)\n",
    "\n",
    "    x=Conv2D(72,(3,3),padding=\"same\")(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "\n",
    "    x1=Conv2D(72,(3,3),padding=\"same\")(x)\n",
    "    x1=Activation(\"relu\")(x1)\n",
    "    x1=MaxPooling2D(pool_size=(2,2))(x1)\n",
    "    x2=Conv2D(32,(5,5),padding=\"same\")(x)\n",
    "    x2=Activation(\"relu\")(x2)\n",
    "    x2=MaxPooling2D(pool_size=(2,2))(x2)\n",
    "    x3=Conv2D(32,(7,7),padding=\"same\")(x)\n",
    "    x3=Activation(\"relu\")(x3)\n",
    "    x3=MaxPooling2D(pool_size=(2,2))(x3)\n",
    "\n",
    "    x=concatenate([x1,x2,x3],axis=3)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=spatial_attention(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "\n",
    "    x=Dense(84, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    x=Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(l=0.001),bias_regularizer=regularizers.l2(l=0.001))(x)\n",
    "    x=Dropout(0.1)(x)\n",
    "    outputl=Dense(1,activation=\"sigmoid\")(x)\n",
    "    model=Model(inputs=inputl,outputs=outputl)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 763/1133 [===================>..........] - ETA: 48s - loss: 0.9066 - accuracy: 0.5008"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=20,batch_size=32,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"attention_20e.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
