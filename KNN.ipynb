{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# KNN classifier\n",
    "In this part, we will use knn algorithm to classify whether the data is cat or dog.\n",
    "We will convert a 128128 image into a 128128 dimensional vector, where each component represents the grayscale value of the corresponding pixel. By calculating the Manhattan distance, we select the majority class from the k nearest points to the predicted point, and predict the image to belong to that class.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## split the cat and dog data into train and test\n",
    "Because the data is a little unbalanced, we will choose the same number of cat and dog data for training.\n",
    "The number of cat and dog image are 9997 and 10288 respectively. We will choose 8000 cat and dog images for training and 1997 cat and 2288 dog images for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# load the data\n",
    "cat_path = '.\\data\\cat'\n",
    "dog_path = '.\\data\\dog'\n",
    "cat_list = os.listdir(cat_path)\n",
    "dog_list = os.listdir(dog_path)\n",
    "cat_list = [os.path.join(cat_path, i) for i in cat_list]\n",
    "dog_list = [os.path.join(dog_path, i) for i in dog_list]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "cat_train, cat_test = train_test_split(cat_list, test_size=1997/9997, random_state=42)\n",
    "dog_train, dog_test = train_test_split(dog_list, test_size=2288/10288, random_state=42)\n",
    "train_list = cat_train + dog_train\n",
    "test_list = cat_test + dog_test\n",
    "train_label = [0] * len(cat_train) + [1] * len(dog_train)\n",
    "test_label = [0] * len(cat_test) + [1] * len(dog_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# convert the image into a vector\n",
    "for i in range(len(train_list)):\n",
    "    img = cv.imread(train_list[i], 0)\n",
    "    img = img.reshape(1, -1)\n",
    "    if i == 0:\n",
    "        train_data = img\n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, img), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for i in range(len(test_list)):\n",
    "    img = cv.imread(test_list[i], 0)\n",
    "    img = img.reshape(1, -1)\n",
    "    if i == 0:\n",
    "        test_data = img\n",
    "    else:\n",
    "        test_data = np.concatenate((test_data, img), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1 accuracy= 0.5617269544924154\n",
      "k= 1 confusion matrix= [[1168  829]\n",
      " [1049 1239]]\n",
      "k= 1 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55      1997\n",
      "           1       0.60      0.54      0.57      2288\n",
      "\n",
      "    accuracy                           0.56      4285\n",
      "   macro avg       0.56      0.56      0.56      4285\n",
      "weighted avg       0.57      0.56      0.56      4285\n",
      "\n",
      "k= 2 accuracy= 0.5617269544924154\n",
      "k= 2 confusion matrix= [[1168  829]\n",
      " [1049 1239]]\n",
      "k= 2 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55      1997\n",
      "           1       0.60      0.54      0.57      2288\n",
      "\n",
      "    accuracy                           0.56      4285\n",
      "   macro avg       0.56      0.56      0.56      4285\n",
      "weighted avg       0.57      0.56      0.56      4285\n",
      "\n",
      "k= 3 accuracy= 0.5757292882147025\n",
      "k= 3 confusion matrix= [[1172  825]\n",
      " [ 993 1295]]\n",
      "k= 3 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.56      1997\n",
      "           1       0.61      0.57      0.59      2288\n",
      "\n",
      "    accuracy                           0.58      4285\n",
      "   macro avg       0.58      0.58      0.58      4285\n",
      "weighted avg       0.58      0.58      0.58      4285\n",
      "\n",
      "k= 4 accuracy= 0.569661610268378\n",
      "k= 4 confusion matrix= [[1179  818]\n",
      " [1026 1262]]\n",
      "k= 4 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.56      1997\n",
      "           1       0.61      0.55      0.58      2288\n",
      "\n",
      "    accuracy                           0.57      4285\n",
      "   macro avg       0.57      0.57      0.57      4285\n",
      "weighted avg       0.57      0.57      0.57      4285\n",
      "\n",
      "k= 5 accuracy= 0.574095682613769\n",
      "k= 5 confusion matrix= [[1170  827]\n",
      " [ 998 1290]]\n",
      "k= 5 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.59      0.56      1997\n",
      "           1       0.61      0.56      0.59      2288\n",
      "\n",
      "    accuracy                           0.57      4285\n",
      "   macro avg       0.57      0.57      0.57      4285\n",
      "weighted avg       0.58      0.57      0.57      4285\n",
      "\n",
      "k= 6 accuracy= 0.5803967327887981\n",
      "k= 6 confusion matrix= [[1177  820]\n",
      " [ 978 1310]]\n",
      "k= 6 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57      1997\n",
      "           1       0.62      0.57      0.59      2288\n",
      "\n",
      "    accuracy                           0.58      4285\n",
      "   macro avg       0.58      0.58      0.58      4285\n",
      "weighted avg       0.58      0.58      0.58      4285\n",
      "\n",
      "k= 7 accuracy= 0.5810968494749125\n",
      "k= 7 confusion matrix= [[1158  839]\n",
      " [ 956 1332]]\n",
      "k= 7 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.56      1997\n",
      "           1       0.61      0.58      0.60      2288\n",
      "\n",
      "    accuracy                           0.58      4285\n",
      "   macro avg       0.58      0.58      0.58      4285\n",
      "weighted avg       0.58      0.58      0.58      4285\n",
      "\n",
      "k= 8 accuracy= 0.5871645274212369\n",
      "k= 8 confusion matrix= [[1157  840]\n",
      " [ 929 1359]]\n",
      "k= 8 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.57      1997\n",
      "           1       0.62      0.59      0.61      2288\n",
      "\n",
      "    accuracy                           0.59      4285\n",
      "   macro avg       0.59      0.59      0.59      4285\n",
      "weighted avg       0.59      0.59      0.59      4285\n",
      "\n",
      "k= 9 accuracy= 0.5936989498249708\n",
      "k= 9 confusion matrix= [[1165  832]\n",
      " [ 909 1379]]\n",
      "k= 9 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      1997\n",
      "           1       0.62      0.60      0.61      2288\n",
      "\n",
      "    accuracy                           0.59      4285\n",
      "   macro avg       0.59      0.59      0.59      4285\n",
      "weighted avg       0.59      0.59      0.59      4285\n",
      "\n",
      "k= 10 accuracy= 0.5934655775962661\n",
      "k= 10 confusion matrix= [[1160  837]\n",
      " [ 905 1383]]\n",
      "k= 10 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57      1997\n",
      "           1       0.62      0.60      0.61      2288\n",
      "\n",
      "    accuracy                           0.59      4285\n",
      "   macro avg       0.59      0.59      0.59      4285\n",
      "weighted avg       0.59      0.59      0.59      4285\n",
      "\n",
      "k= 11 accuracy= 0.5960326721120187\n",
      "k= 11 confusion matrix= [[1156  841]\n",
      " [ 890 1398]]\n",
      "k= 11 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.57      1997\n",
      "           1       0.62      0.61      0.62      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.59      0.59      0.59      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 12 accuracy= 0.5990665110851808\n",
      "k= 12 confusion matrix= [[1165  832]\n",
      " [ 886 1402]]\n",
      "k= 12 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58      1997\n",
      "           1       0.63      0.61      0.62      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 13 accuracy= 0.59463243873979\n",
      "k= 13 confusion matrix= [[1142  855]\n",
      " [ 882 1406]]\n",
      "k= 13 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57      1997\n",
      "           1       0.62      0.61      0.62      2288\n",
      "\n",
      "    accuracy                           0.59      4285\n",
      "   macro avg       0.59      0.59      0.59      4285\n",
      "weighted avg       0.59      0.59      0.59      4285\n",
      "\n",
      "k= 14 accuracy= 0.5971995332555425\n",
      "k= 14 confusion matrix= [[1150  847]\n",
      " [ 879 1409]]\n",
      "k= 14 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.57      1997\n",
      "           1       0.62      0.62      0.62      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 15 accuracy= 0.6\n",
      "k= 15 confusion matrix= [[1134  863]\n",
      " [ 851 1437]]\n",
      "k= 15 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57      1997\n",
      "           1       0.62      0.63      0.63      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 16 accuracy= 0.6049008168028005\n",
      "k= 16 confusion matrix= [[1146  851]\n",
      " [ 842 1446]]\n",
      "k= 16 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.58      1997\n",
      "           1       0.63      0.63      0.63      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 17 accuracy= 0.6067677946324388\n",
      "k= 17 confusion matrix= [[1142  855]\n",
      " [ 830 1458]]\n",
      "k= 17 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.58      1997\n",
      "           1       0.63      0.64      0.63      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 18 accuracy= 0.6060676779463244\n",
      "k= 18 confusion matrix= [[1148  849]\n",
      " [ 839 1449]]\n",
      "k= 18 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.58      1997\n",
      "           1       0.63      0.63      0.63      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 19 accuracy= 0.6056009334889149\n",
      "k= 19 confusion matrix= [[1134  863]\n",
      " [ 827 1461]]\n",
      "k= 19 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57      1997\n",
      "           1       0.63      0.64      0.63      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 20 accuracy= 0.6039673278879814\n",
      "k= 20 confusion matrix= [[1131  866]\n",
      " [ 831 1457]]\n",
      "k= 20 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57      1997\n",
      "           1       0.63      0.64      0.63      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 21 accuracy= 0.6072345390898483\n",
      "k= 21 confusion matrix= [[1130  867]\n",
      " [ 816 1472]]\n",
      "k= 21 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57      1997\n",
      "           1       0.63      0.64      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 22 accuracy= 0.6107351225204201\n",
      "k= 22 confusion matrix= [[1127  870]\n",
      " [ 798 1490]]\n",
      "k= 22 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57      1997\n",
      "           1       0.63      0.65      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 23 accuracy= 0.6084014002333722\n",
      "k= 23 confusion matrix= [[1109  888]\n",
      " [ 790 1498]]\n",
      "k= 23 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57      1997\n",
      "           1       0.63      0.65      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 24 accuracy= 0.6072345390898483\n",
      "k= 24 confusion matrix= [[1115  882]\n",
      " [ 801 1487]]\n",
      "k= 24 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57      1997\n",
      "           1       0.63      0.65      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 25 accuracy= 0.6114352392065344\n",
      "k= 25 confusion matrix= [[1108  889]\n",
      " [ 776 1512]]\n",
      "k= 25 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.55      0.57      1997\n",
      "           1       0.63      0.66      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 26 accuracy= 0.6028004667444574\n",
      "k= 26 confusion matrix= [[1099  898]\n",
      " [ 804 1484]]\n",
      "k= 26 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56      1997\n",
      "           1       0.62      0.65      0.64      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 27 accuracy= 0.606534422403734\n",
      "k= 27 confusion matrix= [[1087  910]\n",
      " [ 776 1512]]\n",
      "k= 27 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56      1997\n",
      "           1       0.62      0.66      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 28 accuracy= 0.6042007001166861\n",
      "k= 28 confusion matrix= [[1088  909]\n",
      " [ 787 1501]]\n",
      "k= 28 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56      1997\n",
      "           1       0.62      0.66      0.64      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 29 accuracy= 0.6049008168028005\n",
      "k= 29 confusion matrix= [[1076  921]\n",
      " [ 772 1516]]\n",
      "k= 29 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56      1997\n",
      "           1       0.62      0.66      0.64      2288\n",
      "\n",
      "    accuracy                           0.60      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.60      0.60      4285\n",
      "\n",
      "k= 30 accuracy= 0.606534422403734\n",
      "k= 30 confusion matrix= [[1087  910]\n",
      " [ 776 1512]]\n",
      "k= 30 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56      1997\n",
      "           1       0.62      0.66      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 31 accuracy= 0.6060676779463244\n",
      "k= 31 confusion matrix= [[1060  937]\n",
      " [ 751 1537]]\n",
      "k= 31 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.67      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.60      0.61      0.60      4285\n",
      "\n",
      "k= 32 accuracy= 0.6070011668611435\n",
      "k= 32 confusion matrix= [[1073  924]\n",
      " [ 760 1528]]\n",
      "k= 32 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.56      1997\n",
      "           1       0.62      0.67      0.64      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 33 accuracy= 0.6081680280046674\n",
      "k= 33 confusion matrix= [[1062  935]\n",
      " [ 744 1544]]\n",
      "k= 33 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.67      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 34 accuracy= 0.607467911318553\n",
      "k= 34 confusion matrix= [[1068  929]\n",
      " [ 753 1535]]\n",
      "k= 34 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.67      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.60      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 35 accuracy= 0.6107351225204201\n",
      "k= 35 confusion matrix= [[1068  929]\n",
      " [ 739 1549]]\n",
      "k= 35 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.63      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 36 accuracy= 0.6126021003500584\n",
      "k= 36 confusion matrix= [[1074  923]\n",
      " [ 737 1551]]\n",
      "k= 36 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.56      1997\n",
      "           1       0.63      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 37 accuracy= 0.6084014002333722\n",
      "k= 37 confusion matrix= [[1051  946]\n",
      " [ 732 1556]]\n",
      "k= 37 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 38 accuracy= 0.6114352392065344\n",
      "k= 38 confusion matrix= [[1067  930]\n",
      " [ 735 1553]]\n",
      "k= 38 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.63      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 39 accuracy= 0.6084014002333722\n",
      "k= 39 confusion matrix= [[1049  948]\n",
      " [ 730 1558]]\n",
      "k= 39 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 40 accuracy= 0.6102683780630105\n",
      "k= 40 confusion matrix= [[1059  938]\n",
      " [ 732 1556]]\n",
      "k= 40 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 41 accuracy= 0.6088681446907818\n",
      "k= 41 confusion matrix= [[1051  946]\n",
      " [ 730 1558]]\n",
      "k= 41 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 42 accuracy= 0.6112018669778296\n",
      "k= 42 confusion matrix= [[1052  945]\n",
      " [ 721 1567]]\n",
      "k= 42 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 43 accuracy= 0.6114352392065344\n",
      "k= 43 confusion matrix= [[1043  954]\n",
      " [ 711 1577]]\n",
      "k= 43 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.56      1997\n",
      "           1       0.62      0.69      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 44 accuracy= 0.6095682613768961\n",
      "k= 44 confusion matrix= [[1052  945]\n",
      " [ 728 1560]]\n",
      "k= 44 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      1997\n",
      "           1       0.62      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 45 accuracy= 0.6088681446907818\n",
      "k= 45 confusion matrix= [[1039  958]\n",
      " [ 718 1570]]\n",
      "k= 45 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55      1997\n",
      "           1       0.62      0.69      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.60      0.60      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 46 accuracy= 0.6128354725787631\n",
      "k= 46 confusion matrix= [[1056  941]\n",
      " [ 718 1570]]\n",
      "k= 46 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56      1997\n",
      "           1       0.63      0.69      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n",
      "k= 47 accuracy= 0.611901983663944\n",
      "k= 47 confusion matrix= [[1044  953]\n",
      " [ 710 1578]]\n",
      "k= 47 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56      1997\n",
      "           1       0.62      0.69      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn classifier\n",
    "acc=[]\n",
    "cml=[]\n",
    "repl=[]\n",
    "for k in range(1,48):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k,weights=\"distance\",algorithm=\"auto\",p=1,metric=\"minkowski\")\n",
    "    knn.fit(train_data, train_label)\n",
    "    pred = knn.predict(test_data)\n",
    "    acc.append(accuracy_score(test_label, pred))\n",
    "    cml.append(confusion_matrix(test_label, pred))\n",
    "    repl.append(classification_report(test_label, pred))\n",
    "    print(\"k=\",k,\"accuracy=\",accuracy_score(test_label, pred))\n",
    "    print(\"k=\",k,\"confusion matrix=\",confusion_matrix(test_label, pred))\n",
    "    print(\"k=\",k,\"classification report=\",classification_report(test_label, pred))\n",
    "#acc5=accuracy_score(test_label, pred)\n",
    "#print('accuracy: ', accuracy_score(test_label, pred))\n",
    "#print('confusion matrix: ', confusion_matrix(test_label, pred))\n",
    "#print('classification report: ', classification_report(test_label, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the accuracy\n",
    "plt.plot(range(1,48), acc)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is obvious that the accuracy is the highest when k=36 and 46. So we will choose k=36 and 46 to do the following analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 36 accuracy= 0.6126021003500584\n",
      "k= 36 confusion matrix= [[1074  923]\n",
      " [ 737 1551]]\n",
      "k= 36 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.56      1997\n",
      "           1       0.63      0.68      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=36,weights=\"distance\",algorithm=\"auto\",p=1,metric=\"minkowski\")\n",
    "knn.fit(train_data, train_label)\n",
    "pred = knn.predict(test_data)\n",
    "print(\"k=\",36,\"accuracy=\",accuracy_score(test_label, pred))\n",
    "print(\"k=\",36,\"confusion matrix=\",confusion_matrix(test_label, pred))\n",
    "print(\"k=\",36,\"classification report=\",classification_report(test_label, pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label, pred)\n",
    "#plot the confusion matrix and show the number of each class\n",
    "f=plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm,annot=True, fmt='d',cmap=\"Blues\", cbar=False,xticklabels=['cat', 'dog'],yticklabels=['cat', 'dog'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 46 accuracy= 0.6128354725787631\n",
      "k= 46 confusion matrix= [[1056  941]\n",
      " [ 718 1570]]\n",
      "k= 46 classification report=               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56      1997\n",
      "           1       0.63      0.69      0.65      2288\n",
      "\n",
      "    accuracy                           0.61      4285\n",
      "   macro avg       0.61      0.61      0.61      4285\n",
      "weighted avg       0.61      0.61      0.61      4285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=46,weights=\"distance\",algorithm=\"auto\",p=1,metric=\"minkowski\")\n",
    "knn.fit(train_data, train_label)\n",
    "pred = knn.predict(test_data)\n",
    "print(\"k=\",46,\"accuracy=\",accuracy_score(test_label, pred))\n",
    "print(\"k=\",46,\"confusion matrix=\",confusion_matrix(test_label, pred))\n",
    "print(\"k=\",46,\"classification report=\",classification_report(test_label, pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label, pred)\n",
    "#plot the confusion matrix and show the number of each class\n",
    "f=plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm,annot=True, fmt='d',cmap=\"Blues\", cbar=False,xticklabels=['cat', 'dog'],yticklabels=['cat', 'dog'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy is about 61.3%. It cannot reach our goal,so we need to change the way to classify."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
